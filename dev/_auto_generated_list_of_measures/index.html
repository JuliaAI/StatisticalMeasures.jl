<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>The Measures · StatisticalMeasures.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">StatisticalMeasures.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Overview</a></li><li><a class="tocitem" href="../examples_of_usage/">Examples of usage</a></li><li class="is-active"><a class="tocitem" href>The Measures</a><ul class="internal"><li><a class="tocitem" href="#Scientific-type-of-observations"><span>Scientific type of observations</span></a></li><li><a class="tocitem" href="#On-multi-target-measures-and-tabular-data"><span>On multi-target measures and tabular data</span></a></li><li><a class="tocitem" href="#Classification-measures-(non-probabilistic)"><span>Classification measures (non-probabilistic)</span></a></li><li><a class="tocitem" href="#Regression-measures-(non-probabilistic)"><span>Regression measures (non-probabilistic)</span></a></li><li><a class="tocitem" href="#Probabilistic-measures"><span>Probabilistic measures</span></a></li><li><a class="tocitem" href="#aliases"><span>List of aliases</span></a></li><li><a class="tocitem" href="#Reference"><span>Reference</span></a></li></ul></li><li><a class="tocitem" href="../confusion_matrices/">Confusion Matrices</a></li><li><a class="tocitem" href="../roc/">Receiver Operator Characteristics</a></li><li><a class="tocitem" href="../tools/">Tools</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>The Measures</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>The Measures</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/dev/docs/src/_auto_generated_list_of_measures.md#L" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="The-Measures"><a class="docs-heading-anchor" href="#The-Measures">The Measures</a><a id="The-Measures-1"></a><a class="docs-heading-anchor-permalink" href="#The-Measures" title="Permalink"></a></h1><h3 id="Quick-links"><a class="docs-heading-anchor" href="#Quick-links">Quick links</a><a id="Quick-links-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-links" title="Permalink"></a></h3><ul><li><a href="#aliases">List of aliases</a></li><li><a href="#Classification-measures-(non-probabilistic)">Classification measures (non-probabilistic)</a></li><li><a href="#Regression-measures-(non-probabilistic)">Regression measures (non-probabilistic)</a></li><li><a href="#Probabilistic-measures">Probabilistic measures</a></li></ul><h2 id="Scientific-type-of-observations"><a class="docs-heading-anchor" href="#Scientific-type-of-observations">Scientific type of observations</a><a id="Scientific-type-of-observations-1"></a><a class="docs-heading-anchor-permalink" href="#Scientific-type-of-observations" title="Permalink"></a></h2><p>Measures can be classified according to the <a href="https://juliaai.github.io/ScientificTypes.jl/dev/">scientific type</a> of the target observations they consume (given by the value of the trait, <a href="../reference/#StatisticalMeasuresBase.observation_scitype"><code>StatisticalMeasuresBase.observation_scitype(measure)</code></a>):</p><table><tr><th style="text-align: left">observation scitype</th><th style="text-align: left">meaning</th></tr><tr><td style="text-align: left"><code>Finite</code></td><td style="text-align: left">general classification</td></tr><tr><td style="text-align: left"><code>Finite{2}=Binary</code></td><td style="text-align: left">binary classification</td></tr><tr><td style="text-align: left"><code>OrderedFactor</code></td><td style="text-align: left">classification (class order matters)</td></tr><tr><td style="text-align: left"><code>OrderedFactor{2}</code></td><td style="text-align: left">binary classification (order matters)</td></tr><tr><td style="text-align: left"><code>Continuous</code></td><td style="text-align: left">regression</td></tr><tr><td style="text-align: left"><code>Infinite</code></td><td style="text-align: left">regression, including integer targets for <code>Count</code> data</td></tr><tr><td style="text-align: left"><code>AbstractArray{T}</code></td><td style="text-align: left">multitarget version of <code>T</code>, some tabular data okay</td></tr></table><p>Measures are not strict about data conforming to the declared observation scitype. For example, where <code>OrderedFactor{2}</code> is expected, <code>Finite{2}</code> will work, and in fact most eltypes will work, so long as there are only two classes. However, you may get warnings that mitigate possible misinterpretations of results (e.g., about which class is the &quot;positive&quot; one). Some warnings can be suppressed by explicitly specifying measure parameters, such as <code>levels</code>.</p><p>To be 100% safe and avoid warnings, use data with the recommended observation scitype.</p><h2 id="On-multi-target-measures-and-tabular-data"><a class="docs-heading-anchor" href="#On-multi-target-measures-and-tabular-data">On multi-target measures and tabular data</a><a id="On-multi-target-measures-and-tabular-data-1"></a><a class="docs-heading-anchor-permalink" href="#On-multi-target-measures-and-tabular-data" title="Permalink"></a></h2><p>All multi-target measures below (the ones with <code>AbstractArray</code> observation scitypes) also handle some forms of tabular input, including <code>DataFrame</code>s and Julia&#39;s native &quot;row table&quot; and &quot;column table&quot; formats. This is not reflected by the declared observation scitype. Instead, you can inspect the trait <a href="../reference/#StatisticalMeasuresBase.can_consume_tables"><code>StatisticalMeasuresBase.can_consume_tables</code></a> or consult the measure document string.</p><h2 id="Classification-measures-(non-probabilistic)"><a class="docs-heading-anchor" href="#Classification-measures-(non-probabilistic)">Classification measures (non-probabilistic)</a><a id="Classification-measures-(non-probabilistic)-1"></a><a class="docs-heading-anchor-permalink" href="#Classification-measures-(non-probabilistic)" title="Permalink"></a></h2><table><tr><th style="text-align: left">constructor / instance aliases</th><th style="text-align: left">observation scitype</th></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.FScore"><code>FScore</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.FalseDiscoveryRate"><code>FalseDiscoveryRate</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegative"><code>FalseNegative</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegativeRate"><code>FalseNegativeRate</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositive"><code>FalsePositive</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositiveRate"><code>FalsePositiveRate</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.NegativePredictiveValue"><code>NegativePredictiveValue</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegative"><code>TrueNegative</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.TruePositive"><code>TruePositive</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a></td><td style="text-align: left"><code>Union{Missing, OrderedFactor{2}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFScore"><code>MulticlassFScore</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseDiscoveryRate"><code>MulticlassFalseDiscoveryRate</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegative"><code>MulticlassFalseNegative</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegativeRate"><code>MulticlassFalseNegativeRate</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositive"><code>MulticlassFalsePositive</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositiveRate"><code>MulticlassFalsePositiveRate</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassNegativePredictiveValue"><code>MulticlassNegativePredictiveValue</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassPositivePredictiveValue"><code>MulticlassPositivePredictiveValue</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegative"><code>MulticlassTrueNegative</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>MulticlassTrueNegativeRate</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositive"><code>MulticlassTruePositive</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a></td><td style="text-align: left"><code>Union{Missing, Multiclass}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.Accuracy"><code>Accuracy</code></a></td><td style="text-align: left"><code>Union{Missing, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.BalancedAccuracy"><code>BalancedAccuracy</code></a></td><td style="text-align: left"><code>Union{Missing, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a></td><td style="text-align: left"><code>Union{Missing, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.Kappa"><code>Kappa</code></a></td><td style="text-align: left"><code>Union{Missing, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MatthewsCorrelation"><code>MatthewsCorrelation</code></a></td><td style="text-align: left"><code>Union{Missing, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MisclassificationRate"><code>MisclassificationRate</code></a></td><td style="text-align: left"><code>Union{Missing, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetAccuracy"><code>MultitargetAccuracy</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Finite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetMisclassificationRate"><code>MultitargetMisclassificationRate</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Finite}}</code></td></tr></table><h2 id="Regression-measures-(non-probabilistic)"><a class="docs-heading-anchor" href="#Regression-measures-(non-probabilistic)">Regression measures (non-probabilistic)</a><a id="Regression-measures-(non-probabilistic)-1"></a><a class="docs-heading-anchor-permalink" href="#Regression-measures-(non-probabilistic)" title="Permalink"></a></h2><table><tr><th style="text-align: left">constructor / instance aliases</th><th style="text-align: left">observation scitype</th></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.LPSumLoss"><code>LPSumLoss</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.LogCoshLoss"><code>LogCoshLoss</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MeanAbsoluteProportionalError"><code>MeanAbsoluteProportionalError</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.RSquared"><code>RSquared</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredError"><code>RootMeanSquaredError</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredLogError"><code>RootMeanSquaredLogError</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredLogProportionalError"><code>RootMeanSquaredLogProportionalError</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredProportionalError"><code>RootMeanSquaredProportionalError</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPLoss"><code>MultitargetLPLoss</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPSumLoss"><code>MultitargetLPSumLoss</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLogCoshLoss"><code>MultitargetLogCoshLoss</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetMeanAbsoluteProportionalError"><code>MultitargetMeanAbsoluteProportionalError</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredError"><code>MultitargetRootMeanSquaredError</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredLogError"><code>MultitargetRootMeanSquaredLogError</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredLogProportionalError"><code>MultitargetRootMeanSquaredLogProportionalError</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredProportionalError"><code>MultitargetRootMeanSquaredProportionalError</code></a></td><td style="text-align: left"><code>AbstractArray{&lt;:Union{Missing, Infinite}}</code></td></tr></table><h2 id="Probabilistic-measures"><a class="docs-heading-anchor" href="#Probabilistic-measures">Probabilistic measures</a><a id="Probabilistic-measures-1"></a><a class="docs-heading-anchor-permalink" href="#Probabilistic-measures" title="Permalink"></a></h2><p>These are measures where each prediction is a probability mass or density function, over the space of possible ground truth observations. Specifically, <a href="../reference/#StatisticalMeasuresBase.kind_of_proxy"><code>StatisticalMeasuresBase.kind_of_proxy(measure)</code></a> <code>== LearnAPI.Distribution()</code>.</p><table><tr><th style="text-align: left">constructor / instance aliases</th><th style="text-align: left">observation scitype</th></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.BrierLoss"><code>BrierLoss</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.BrierScore"><code>BrierScore</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.LogLoss"><code>LogLoss</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.LogScore"><code>LogScore</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.SphericalScore"><code>SphericalScore</code></a></td><td style="text-align: left"><code>Union{Missing, Infinite, Finite}</code></td></tr><tr><td style="text-align: left"><a href="#StatisticalMeasures.AreaUnderCurve"><code>AreaUnderCurve</code></a></td><td style="text-align: left"><code>Binary</code></td></tr></table><h2 id="aliases"><a class="docs-heading-anchor" href="#aliases">List of aliases</a><a id="aliases-1"></a><a class="docs-heading-anchor-permalink" href="#aliases" title="Permalink"></a></h2><p>Some of the measures constructed using specific parameter values have pre-defined names associated with them that are exported by StatisticalMeasures.jl These are called <em>aliases</em>.</p><table><tr><th style="text-align: left">alias</th><th style="text-align: left">constructed with</th></tr><tr><td style="text-align: left"><code>accuracy</code></td><td style="text-align: left"><a href="#StatisticalMeasures.Accuracy"><code>Accuracy</code></a></td></tr><tr><td style="text-align: left"><code>area_under_curve</code></td><td style="text-align: left"><a href="#StatisticalMeasures.AreaUnderCurve"><code>AreaUnderCurve</code></a></td></tr><tr><td style="text-align: left"><code>auc</code></td><td style="text-align: left"><a href="#StatisticalMeasures.AreaUnderCurve"><code>AreaUnderCurve</code></a></td></tr><tr><td style="text-align: left"><code>bac</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BalancedAccuracy"><code>BalancedAccuracy</code></a></td></tr><tr><td style="text-align: left"><code>bacc</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BalancedAccuracy"><code>BalancedAccuracy</code></a></td></tr><tr><td style="text-align: left"><code>balanced_accuracy</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BalancedAccuracy"><code>BalancedAccuracy</code></a></td></tr><tr><td style="text-align: left"><code>brier_loss</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BrierLoss"><code>BrierLoss</code></a></td></tr><tr><td style="text-align: left"><code>brier_score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BrierScore"><code>BrierScore</code></a></td></tr><tr><td style="text-align: left"><code>confmat</code></td><td style="text-align: left"><a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a></td></tr><tr><td style="text-align: left"><code>confusion_matrix</code></td><td style="text-align: left"><a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a></td></tr><tr><td style="text-align: left"><code>cross_entropy</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LogLoss"><code>LogLoss</code></a></td></tr><tr><td style="text-align: left"><code>cross_entropy</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BrierLoss"><code>BrierLoss</code></a></td></tr><tr><td style="text-align: left"><code>f1score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FScore"><code>FScore</code></a></td></tr><tr><td style="text-align: left"><code>fallout</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositiveRate"><code>FalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>false_discovery_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseDiscoveryRate"><code>FalseDiscoveryRate</code></a></td></tr><tr><td style="text-align: left"><code>false_negative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegativeRate"><code>FalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>false_negative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegative"><code>FalseNegative</code></a></td></tr><tr><td style="text-align: left"><code>false_positive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositiveRate"><code>FalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>false_positive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositive"><code>FalsePositive</code></a></td></tr><tr><td style="text-align: left"><code>falsediscovery_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseDiscoveryRate"><code>FalseDiscoveryRate</code></a></td></tr><tr><td style="text-align: left"><code>falsenegative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegativeRate"><code>FalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>falsenegative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegative"><code>FalseNegative</code></a></td></tr><tr><td style="text-align: left"><code>falsepositive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositiveRate"><code>FalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>falsepositive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositive"><code>FalsePositive</code></a></td></tr><tr><td style="text-align: left"><code>fdr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseDiscoveryRate"><code>FalseDiscoveryRate</code></a></td></tr><tr><td style="text-align: left"><code>fnr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegativeRate"><code>FalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>fpr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalsePositiveRate"><code>FalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>hit_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>kappa</code></td><td style="text-align: left"><a href="#StatisticalMeasures.Kappa"><code>Kappa</code></a></td></tr><tr><td style="text-align: left"><code>l1_sum</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPSumLoss"><code>LPSumLoss</code></a></td></tr><tr><td style="text-align: left"><code>l1</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a></td></tr><tr><td style="text-align: left"><code>l2_sum</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPSumLoss"><code>LPSumLoss</code></a></td></tr><tr><td style="text-align: left"><code>l2</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a></td></tr><tr><td style="text-align: left"><code>log_cosh_loss</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LogCoshLoss"><code>LogCoshLoss</code></a></td></tr><tr><td style="text-align: left"><code>log_cosh</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LogCoshLoss"><code>LogCoshLoss</code></a></td></tr><tr><td style="text-align: left"><code>log_loss</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LogLoss"><code>LogLoss</code></a></td></tr><tr><td style="text-align: left"><code>log_score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LogScore"><code>LogScore</code></a></td></tr><tr><td style="text-align: left"><code>macro_f1score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFScore"><code>MulticlassFScore</code></a></td></tr><tr><td style="text-align: left"><code>mae</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a></td></tr><tr><td style="text-align: left"><code>mape</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MeanAbsoluteProportionalError"><code>MeanAbsoluteProportionalError</code></a></td></tr><tr><td style="text-align: left"><code>matthews_correlation</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MatthewsCorrelation"><code>MatthewsCorrelation</code></a></td></tr><tr><td style="text-align: left"><code>mav</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a></td></tr><tr><td style="text-align: left"><code>mcc</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MatthewsCorrelation"><code>MatthewsCorrelation</code></a></td></tr><tr><td style="text-align: left"><code>mcr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MisclassificationRate"><code>MisclassificationRate</code></a></td></tr><tr><td style="text-align: left"><code>mean_absolute_error</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a></td></tr><tr><td style="text-align: left"><code>mean_absolute_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a></td></tr><tr><td style="text-align: left"><code>micro_f1score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFScore"><code>MulticlassFScore</code></a></td></tr><tr><td style="text-align: left"><code>misclassification_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MisclassificationRate"><code>MisclassificationRate</code></a></td></tr><tr><td style="text-align: left"><code>miss_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.FalseNegativeRate"><code>FalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_f1score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFScore"><code>MulticlassFScore</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_fallout</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositiveRate"><code>MulticlassFalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_false_discovery_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseDiscoveryRate"><code>MulticlassFalseDiscoveryRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_false_negative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegativeRate"><code>MulticlassFalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_false_negative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegative"><code>MulticlassFalseNegative</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_false_positive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositiveRate"><code>MulticlassFalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_false_positive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositive"><code>MulticlassFalsePositive</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_falsediscovery_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseDiscoveryRate"><code>MulticlassFalseDiscoveryRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_falsenegative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegativeRate"><code>MulticlassFalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_falsenegative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegative"><code>MulticlassFalseNegative</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_falsepositive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositiveRate"><code>MulticlassFalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_falsepositive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositive"><code>MulticlassFalsePositive</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_fdr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseDiscoveryRate"><code>MulticlassFalseDiscoveryRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_fnr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegativeRate"><code>MulticlassFalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_fpr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalsePositiveRate"><code>MulticlassFalsePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_hit_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_miss_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassFalseNegativeRate"><code>MulticlassFalseNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_negative_predictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassNegativePredictiveValue"><code>MulticlassNegativePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_negativepredictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassNegativePredictiveValue"><code>MulticlassNegativePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_npv</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassNegativePredictiveValue"><code>MulticlassNegativePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_positive_predictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassPositivePredictiveValue"><code>MulticlassPositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_positivepredictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassPositivePredictiveValue"><code>MulticlassPositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_ppv</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassPositivePredictiveValue"><code>MulticlassPositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_precision</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassPositivePredictiveValue"><code>MulticlassPositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_recall</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_selectivity</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>MulticlassTrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_sensitivity</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_specificity</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>MulticlassTrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_tnr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>MulticlassTrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_tpr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_true_negative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>MulticlassTrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_true_negative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegative"><code>MulticlassTrueNegative</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_true_positive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_true_positive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositive"><code>MulticlassTruePositive</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_truenegative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>MulticlassTrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_truenegative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTrueNegative"><code>MulticlassTrueNegative</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_truepositive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>multiclass_truepositive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MulticlassTruePositive"><code>MulticlassTruePositive</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_accuracy</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetAccuracy"><code>MultitargetAccuracy</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_l1_sum</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPSumLoss"><code>MultitargetLPSumLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_l1</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPLoss"><code>MultitargetLPLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_l2_sum</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPSumLoss"><code>MultitargetLPSumLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_l2</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPLoss"><code>MultitargetLPLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_mae</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPLoss"><code>MultitargetLPLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_mape</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetMeanAbsoluteProportionalError"><code>MultitargetMeanAbsoluteProportionalError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_mape</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLogCoshLoss"><code>MultitargetLogCoshLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_mav</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPLoss"><code>MultitargetLPLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_mcr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetMisclassificationRate"><code>MultitargetMisclassificationRate</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_mean_absolute_error</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPLoss"><code>MultitargetLPLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_mean_absolute_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetLPLoss"><code>MultitargetLPLoss</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_misclassification_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetMisclassificationRate"><code>MultitargetMisclassificationRate</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_rms</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredError"><code>MultitargetRootMeanSquaredError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_rmse</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredError"><code>MultitargetRootMeanSquaredError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_rmsl</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredLogError"><code>MultitargetRootMeanSquaredLogError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_rmsle</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredLogError"><code>MultitargetRootMeanSquaredLogError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_rmslp1</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredLogProportionalError"><code>MultitargetRootMeanSquaredLogProportionalError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_rmsp</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredProportionalError"><code>MultitargetRootMeanSquaredProportionalError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_root_mean_squared_error</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredError"><code>MultitargetRootMeanSquaredError</code></a></td></tr><tr><td style="text-align: left"><code>multitarget_root_mean_squared_log_error</code></td><td style="text-align: left"><a href="#StatisticalMeasures.MultitargetRootMeanSquaredLogError"><code>MultitargetRootMeanSquaredLogError</code></a></td></tr><tr><td style="text-align: left"><code>negative_predictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.NegativePredictiveValue"><code>NegativePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>negativepredictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.NegativePredictiveValue"><code>NegativePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>npv</code></td><td style="text-align: left"><a href="#StatisticalMeasures.NegativePredictiveValue"><code>NegativePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>positive_predictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>positivepredictive_value</code></td><td style="text-align: left"><a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>ppv</code></td><td style="text-align: left"><a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>precision</code></td><td style="text-align: left"><a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a></td></tr><tr><td style="text-align: left"><code>quadratic_loss</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BrierLoss"><code>BrierLoss</code></a></td></tr><tr><td style="text-align: left"><code>quadratic_score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.BrierScore"><code>BrierScore</code></a></td></tr><tr><td style="text-align: left"><code>recall</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>rms</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredError"><code>RootMeanSquaredError</code></a></td></tr><tr><td style="text-align: left"><code>rmse</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredError"><code>RootMeanSquaredError</code></a></td></tr><tr><td style="text-align: left"><code>rmsl</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredLogError"><code>RootMeanSquaredLogError</code></a></td></tr><tr><td style="text-align: left"><code>rmsle</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredLogError"><code>RootMeanSquaredLogError</code></a></td></tr><tr><td style="text-align: left"><code>rmslp1</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredLogProportionalError"><code>RootMeanSquaredLogProportionalError</code></a></td></tr><tr><td style="text-align: left"><code>rmsp</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredProportionalError"><code>RootMeanSquaredProportionalError</code></a></td></tr><tr><td style="text-align: left"><code>root_mean_squared_error</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredError"><code>RootMeanSquaredError</code></a></td></tr><tr><td style="text-align: left"><code>root_mean_squared_log_error</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RootMeanSquaredLogError"><code>RootMeanSquaredLogError</code></a></td></tr><tr><td style="text-align: left"><code>rsq</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RSquared"><code>RSquared</code></a></td></tr><tr><td style="text-align: left"><code>rsquared</code></td><td style="text-align: left"><a href="#StatisticalMeasures.RSquared"><code>RSquared</code></a></td></tr><tr><td style="text-align: left"><code>selectivity</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>sensitivity</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>specificity</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>spherical_score</code></td><td style="text-align: left"><a href="#StatisticalMeasures.SphericalScore"><code>SphericalScore</code></a></td></tr><tr><td style="text-align: left"><code>tnr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>tpr</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>true_negative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>true_negative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegative"><code>TrueNegative</code></a></td></tr><tr><td style="text-align: left"><code>true_positive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>true_positive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositive"><code>TruePositive</code></a></td></tr><tr><td style="text-align: left"><code>truenegative_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a></td></tr><tr><td style="text-align: left"><code>truenegative</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TrueNegative"><code>TrueNegative</code></a></td></tr><tr><td style="text-align: left"><code>truepositive_rate</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a></td></tr><tr><td style="text-align: left"><code>truepositive</code></td><td style="text-align: left"><a href="#StatisticalMeasures.TruePositive"><code>TruePositive</code></a></td></tr></table><h2 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.LPLoss" href="#StatisticalMeasures.LPLoss"><code>StatisticalMeasures.LPLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LPLoss(; p=2)</code></pre><p>Return a callable measure for computing the <span>$L^p$</span> loss. Aliases: <code>l1</code>, <code>l2</code>, <code>mae</code>, <code>mav</code>, <code>mean_absolute_error</code>, <code>mean_absolute_value</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>LPLoss</code> constructor (e.g., <code>m = LPLoss()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, return the mean of <span>$|ŷ_i - y_i|^p$</span> over all pairs of observations <span>$(ŷ_i, y_i)$</span> in <code>(ŷ, y)</code>, or more generally, the mean of weighted versions of those values. For the weighted <em>sum</em> use <a href="#StatisticalMeasures.LPSumLoss"><code>LPSumLoss</code></a> instead.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = ``L^p`` loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL45-L77">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetLPLoss" href="#StatisticalMeasures.MultitargetLPLoss"><code>StatisticalMeasures.MultitargetLPLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetLPLoss(; p=2, atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget <span>$L^p$</span> loss. Aliases: <code>multitarget_l1</code>, <code>multitarget_l2</code>, <code>multitarget_mae</code>, <code>multitarget_mav</code>, <code>multitarget_mean_absolute_error</code>, <code>multitarget_mean_absolute_value</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetLPLoss</code> constructor (e.g., <code>m = MultitargetLPLoss()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>AbstractArray{&lt;:Union{Missing,Infinite}}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multitarget ``L^p`` loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL79-L110">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.LPSumLoss" href="#StatisticalMeasures.LPSumLoss"><code>StatisticalMeasures.LPSumLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LPSumLoss(; p=2)</code></pre><p>Return a callable measure for computing the <span>$L^p$</span> sum loss. Aliases: <code>l1_sum</code>, <code>l2_sum</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>LPSumLoss</code> constructor (e.g., <code>m = LPSumLoss()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the (weighted) sum of <span>$|ŷ_i - yᵢ|^p$</span> over all pairs of observations <span>$(ŷ_i, yᵢ)$</span> in <code>(ŷ, y)</code>. For the weighted <em>mean</em> use <a href="#StatisticalMeasures.LPLoss"><code>LPLoss</code></a> instead.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = ``L^p`` sum loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL126-L157">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetLPSumLoss" href="#StatisticalMeasures.MultitargetLPSumLoss"><code>StatisticalMeasures.MultitargetLPSumLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetLPSumLoss(; p=2, atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget <span>$L^p$</span> sum loss. Aliases: <code>multitarget_l1_sum</code>, <code>multitarget_l2_sum</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetLPSumLoss</code> constructor (e.g., <code>m = MultitargetLPSumLoss()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.LPSumLoss"><code>LPSumLoss</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>AbstractArray{&lt;:Union{Missing,Infinite}}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = multitarget ``L^p`` sum loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL148-L179">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.RootMeanSquaredError" href="#StatisticalMeasures.RootMeanSquaredError"><code>StatisticalMeasures.RootMeanSquaredError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RootMeanSquaredError()</code></pre><p>Return a callable measure for computing the root mean squared error. Aliases: <code>rms</code>, <code>rmse</code>, <code>root_mean_squared_error</code>.</p><pre><code class="nohighlight hljs">RootMeanSquaredError()(ŷ, y)
RootMeanSquaredError()(ŷ, y, weights)
RootMeanSquaredError()(ŷ, y, class_weights::AbstractDict)
RootMeanSquaredError()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>RootMeanSquaredError()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>.  Specifically, compute the mean of <span>$|y_i-ŷ_i|^2$</span> over all pairs of observations <span>$(ŷ_i, y_i)$</span> in <code>(ŷ, y)</code>, and return the square root of the result. More generally, pre-multiply the squared deviations by the specified weights.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = root mean squared error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL183-L217">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetRootMeanSquaredError" href="#StatisticalMeasures.MultitargetRootMeanSquaredError"><code>StatisticalMeasures.MultitargetRootMeanSquaredError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetRootMeanSquaredError(; atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget root mean squared error. Aliases: <code>multitarget_rms</code>, <code>multitarget_rmse</code>, <code>multitarget_root_mean_squared_error</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetRootMeanSquaredError</code> constructor (e.g., <code>m = MultitargetRootMeanSquaredError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.RootMeanSquaredError"><code>RootMeanSquaredError</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>AbstractArray{&lt;:Union{Missing,Infinite}}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = multitarget root mean squared error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL207-L238">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.RootMeanSquaredLogError" href="#StatisticalMeasures.RootMeanSquaredLogError"><code>StatisticalMeasures.RootMeanSquaredLogError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RootMeanSquaredLogError()</code></pre><p>Return a callable measure for computing the root mean squared log error. Aliases: <code>rmsl</code>, <code>rmsle</code>, <code>root_mean_squared_log_error</code>.</p><pre><code class="nohighlight hljs">RootMeanSquaredLogError()(ŷ, y)
RootMeanSquaredLogError()(ŷ, y, weights)
RootMeanSquaredLogError()(ŷ, y, class_weights::AbstractDict)
RootMeanSquaredLogError()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>RootMeanSquaredLogError()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, return the mean of <span>$(\log(y)_i - \log(ŷ_i))^2$</span> over all pairs of observations <span>$(ŷ_i, y_i)$</span> in <code>(ŷ, y)</code>, and return the square root of the result. More generally, pre-multiply the values averaged by the specified weights. To include an offset, use <a href="#StatisticalMeasures.RootMeanSquaredLogProportionalError"><code>RootMeanSquaredLogProportionalError</code></a> instead.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = root mean squared log error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL247-L281">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetRootMeanSquaredLogError" href="#StatisticalMeasures.MultitargetRootMeanSquaredLogError"><code>StatisticalMeasures.MultitargetRootMeanSquaredLogError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetRootMeanSquaredLogError(; atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget root mean squared log error. Aliases: <code>multitarget_rmsl</code>, <code>multitarget_rmsle</code>, <code>multitarget_root_mean_squared_log_error</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetRootMeanSquaredLogError</code> constructor (e.g., <code>m = MultitargetRootMeanSquaredLogError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.RootMeanSquaredLogError"><code>RootMeanSquaredLogError</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>AbstractArray{&lt;:Union{Missing,Infinite}}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = multitarget root mean squared log error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL271-L302">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.RootMeanSquaredLogProportionalError" href="#StatisticalMeasures.RootMeanSquaredLogProportionalError"><code>StatisticalMeasures.RootMeanSquaredLogProportionalError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RootMeanSquaredLogProportionalError(; offset=1)</code></pre><p>Return a callable measure for computing the root mean squared log proportional error. Aliases: <code>rmslp1</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>RootMeanSquaredLogProportionalError</code> constructor (e.g., <code>m = RootMeanSquaredLogProportionalError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the mean of <span>$(\log(ŷ_i + δ) - \log(y_i + δ))^2$</span> over all pairs of observations <span>$(ŷ_i, y_i)$</span> in <code>(ŷ, y)</code>, and return the square root. More generally, pre-multiply the values averaged by the specified weights. Here <span>$δ$</span>=<code>offset</code>, which is <code>1</code> by default. This is the same as <a href="#StatisticalMeasures.RootMeanSquaredLogError"><code>RootMeanSquaredLogError</code></a> but adds an offset.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = root mean squared log proportional error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL310-L344">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetRootMeanSquaredLogProportionalError" href="#StatisticalMeasures.MultitargetRootMeanSquaredLogProportionalError"><code>StatisticalMeasures.MultitargetRootMeanSquaredLogProportionalError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetRootMeanSquaredLogProportionalError(; offset=1, atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget root mean squared log proportional error. Aliases: <code>multitarget_rmslp1</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetRootMeanSquaredLogProportionalError</code> constructor (e.g., <code>m = MultitargetRootMeanSquaredLogProportionalError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.RootMeanSquaredLogProportionalError"><code>RootMeanSquaredLogProportionalError</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = multitarget root mean squared log proportional error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL328-L359">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.RootMeanSquaredProportionalError" href="#StatisticalMeasures.RootMeanSquaredProportionalError"><code>StatisticalMeasures.RootMeanSquaredProportionalError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RootMeanSquaredProportionalError(; tol=eps())</code></pre><p>Return a callable measure for computing the root mean squared proportional error. Aliases: <code>rmsp</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>RootMeanSquaredProportionalError</code> constructor (e.g., <code>m = RootMeanSquaredProportionalError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the mean of <span>$(ŷ_i-y_i \over y_i)^2}$</span> over all pairs of observations <span>$(ŷ_i, y_i)$</span> in <code>(ŷ, y)</code>, and return the square root of the result. More generally, pre-multiply the values averaged by the specified weights. Terms for which <span>$|y_i|$</span>&lt;<code>tol</code> are dropped in the summation, but counts still contribute to the mean normalization factor.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = root mean squared proportional error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL362-L396">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetRootMeanSquaredProportionalError" href="#StatisticalMeasures.MultitargetRootMeanSquaredProportionalError"><code>StatisticalMeasures.MultitargetRootMeanSquaredProportionalError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetRootMeanSquaredProportionalError(; tol=eps(), atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget root mean squared proportional error. Aliases: <code>multitarget_rmsp</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetRootMeanSquaredProportionalError</code> constructor (e.g., <code>m = MultitargetRootMeanSquaredProportionalError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.RootMeanSquaredProportionalError"><code>RootMeanSquaredProportionalError</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)
human_name = multitarget root mean squared proportional error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL381-L412">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MeanAbsoluteProportionalError" href="#StatisticalMeasures.MeanAbsoluteProportionalError"><code>StatisticalMeasures.MeanAbsoluteProportionalError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MeanAbsoluteProportionalError(; tol=eps())</code></pre><p>Return a callable measure for computing the mean absolute proportional error. Aliases: <code>mape</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MeanAbsoluteProportionalError</code> constructor (e.g., <code>m = MeanAbsoluteProportionalError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, return the mean of <span>$|ŷ_i-y_i| \over |y_i|$</span> over all pairs of observations <span>$(ŷ_i, y_i)$</span> in <code>(ŷ, y)</code>. More generally, pre-multiply the values averaged by the specified weights. Terms for which <span>$|y_i|$</span>&lt;<code>tol</code> are dropped in the summation, but corresponding weights (or counts) still contribute to the mean normalization factor.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = mean absolute proportional error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL414-L447">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetMeanAbsoluteProportionalError" href="#StatisticalMeasures.MultitargetMeanAbsoluteProportionalError"><code>StatisticalMeasures.MultitargetMeanAbsoluteProportionalError</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetMeanAbsoluteProportionalError(; tol=eps(), atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget mean absolute proportional error. Aliases: <code>multitarget_mape</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetMeanAbsoluteProportionalError</code> constructor (e.g., <code>m = MultitargetMeanAbsoluteProportionalError()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.MeanAbsoluteProportionalError"><code>MeanAbsoluteProportionalError</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multitarget mean absolute proportional error</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL432-L463">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.LogCoshLoss" href="#StatisticalMeasures.LogCoshLoss"><code>StatisticalMeasures.LogCoshLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LogCoshLoss()</code></pre><p>Return a callable measure for computing the log cosh loss. Aliases: <code>log_cosh</code>, <code>log_cosh_loss</code>.</p><pre><code class="nohighlight hljs">LogCoshLoss()(ŷ, y)
LogCoshLoss()(ŷ, y, weights)
LogCoshLoss()(ŷ, y, class_weights::AbstractDict)
LogCoshLoss()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>LogCoshLoss()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Return the mean of <span>$\log(\cosh(ŷ_i-y_i))$</span> over all pairs of observations <span>$(ŷ_i, y_i)$</span> in <code>(ŷ, y)</code>. More generally, pre-multiply the values averaged by the specified weights.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = log cosh loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL463-L495">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetLogCoshLoss" href="#StatisticalMeasures.MultitargetLogCoshLoss"><code>StatisticalMeasures.MultitargetLogCoshLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetLogCoshLoss(; atomic_weights=nothing)</code></pre><p>Return a callable measure for computing the multitarget log cosh loss. Aliases: <code>multitarget_mape</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MultitargetLogCoshLoss</code> constructor (e.g., <code>m = MultitargetLogCoshLoss()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.LogCoshLoss"><code>LogCoshLoss</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Infinite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multitarget log cosh loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL484-L515">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.RSquared" href="#StatisticalMeasures.RSquared"><code>StatisticalMeasures.RSquared</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">RSquared()</code></pre><p>Return a callable measure for computing the R² coefficient. Aliases: <code>rsq</code>, <code>rsquared</code>.</p><pre><code class="nohighlight hljs">RSquared()(ŷ, y)</code></pre><p>Evaluate <code>RSquared()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, return the value of</p><p><span>$1 - \frac{∑ᵢ (ŷ_i- y_i)^2}{∑ᵢ ȳ - y_i)^2},$</span></p><p>where <span>$ȳ$</span> denote the mean of the <span>$y_i$</span>. Also known as R-squared or the coefficient of determination, the <code>R²</code> coefficients is suitable for interpreting linear regression analysis (Chicco et al., <a href="https://doi.org/10.7717/peerj-cs.623">2021</a>).</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Infinite,Missing}</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = R² coefficient</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/continuous.jl#LL542-L574">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.ConfusionMatrix" href="#StatisticalMeasures.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrix</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">ConfusionMatrix(; levels=nothing, rev=false, perm=nothing, checks=true)</code></pre><p>Return a callable measure for computing the confusion matrix. Aliases: <code>confmat</code>, <code>confusion_matrix</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>ConfusionMatrix</code> constructor (e.g., <code>m = ConfusionMatrix()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. See the <a href="https://en.wikipedia.org/wiki/Confusion_matrix"><em>Confusion matrix</em> wikipedia article</a>.</p><p>Elements of a confusion matrix can always be accessed by level - see the example below. To flag the confusion matrix as ordered, and hence index-accessible, do one of the following:</p><ul><li><p>Supply ordered <code>CategoricalArray</code> inputs <code>ŷ</code> and <code>y</code></p></li><li><p>Explicitly specify <code>levels</code> or one of <code>rev</code>, <code>perm</code></p></li></ul><p>Note that <code>==</code> for two confusion matrices is stricter when both are ordered.</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). </p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>For more on the type of object returned and its interface, see <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>ConfusionMatrices.ConfusionMatrix</code></a>.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">
using StatisticalMeasures

y = [&quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;]
ŷ = [&quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;b&quot;, &quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;]

julia&gt; cm = ConfusionMatrix()(ŷ, y)  # or `confmat((ŷ, y)`.

              ┌───────────────────────────┐
              │       Ground Truth        │
┌─────────────┼─────────────┬─────────────┤
│  Predicted  │      a      │      b      │
├─────────────┼─────────────┼─────────────┤
│      a      │      2      │      3      │
├─────────────┼─────────────┼─────────────┤
│      b      │      4      │      1      │
└─────────────┴─────────────┴─────────────┘

julia&gt; cm(&quot;a&quot;, &quot;b&quot;)
3</code></pre><p>Core algorithm:  <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.confmat"><code>ConfusionMatrices.confmat</code></a>.</p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Unoriented()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = confusion matrix</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL101-L193">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MisclassificationRate" href="#StatisticalMeasures.MisclassificationRate"><code>StatisticalMeasures.MisclassificationRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MisclassificationRate()</code></pre><p>Return a callable measure for computing the misclassification rate. Aliases: <code>misclassification_rate</code>, <code>mcr</code>.</p><pre><code class="nohighlight hljs">MisclassificationRate()(ŷ, y)
MisclassificationRate()(ŷ, y, weights)
MisclassificationRate()(ŷ, y, class_weights::AbstractDict)
MisclassificationRate()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>MisclassificationRate()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. That, is, return the proportion of predictions <code>ŷᵢ</code> that are different from the corresponding ground truth <code>yᵢ</code>. More generally, average the specified weights over incorrectly identified observations. Can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>This metric is invariant to class reordering.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). </p><p>See also <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = misclassification rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL148-L185">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetMisclassificationRate" href="#StatisticalMeasures.MultitargetMisclassificationRate"><code>StatisticalMeasures.MultitargetMisclassificationRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetMisclassificationRate()</code></pre><p>Return a callable measure for computing the multitarget misclassification rate. Aliases: <code>multitarget_misclassification_rate</code>, <code>multitarget_mcr</code>.</p><pre><code class="nohighlight hljs">MultitargetMisclassificationRate()(ŷ, y)
MultitargetMisclassificationRate()(ŷ, y, weights)
MultitargetMisclassificationRate()(ŷ, y, class_weights::AbstractDict)
MultitargetMisclassificationRate()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>MultitargetMisclassificationRate()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.MisclassificationRate"><code>MisclassificationRate</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Finite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multitarget misclassification rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL170-L201">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.Accuracy" href="#StatisticalMeasures.Accuracy"><code>StatisticalMeasures.Accuracy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">Accuracy()</code></pre><p>Return a callable measure for computing the accuracy. Aliases: <code>accuracy</code>.</p><pre><code class="nohighlight hljs">Accuracy()(ŷ, y)
Accuracy()(ŷ, y, weights)
Accuracy()(ŷ, y, class_weights::AbstractDict)
Accuracy()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>Accuracy()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. That is, compute the proportion of predictions <code>ŷᵢ</code> that agree with the corresponding ground truth <code>yᵢ</code>. More generally, average the specified weights over all correctly predicted observations.  Can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>This metric is invariant to class reordering.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). </p><p>See also <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = accuracy</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL218-L255">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MultitargetAccuracy" href="#StatisticalMeasures.MultitargetAccuracy"><code>StatisticalMeasures.MultitargetAccuracy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MultitargetAccuracy()</code></pre><p>Return a callable measure for computing the multitarget accuracy. Aliases: <code>multitarget_accuracy</code>.</p><pre><code class="nohighlight hljs">MultitargetAccuracy()(ŷ, y)
MultitargetAccuracy()(ŷ, y, weights)
MultitargetAccuracy()(ŷ, y, class_weights::AbstractDict)
MultitargetAccuracy()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>MultitargetAccuracy()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. Specifically, compute the multi-target version of <a href="#StatisticalMeasures.Accuracy"><code>Accuracy</code></a>. Some kinds of tabular input are supported.</p><p>In array arguments the last dimension is understood to be the observation dimension. The <code>atomic_weights</code> are weights for each component of the multi-target. Unless equal to <code>nothing</code> (uniform weights) the length of <code>atomic_weights</code> will generally match the number of columns of <code>y</code>, if <code>y</code> is a table, or the number of rows of <code>y</code>, if <code>y</code> is a matrix. </p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). Alternatively, <code>y</code> and <code>ŷ</code> can be some types of table, provided elements have the approprate scitype. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = AbstractArray{&lt;:Union{Missing, ScientificTypesBase.Finite}}
can_consume_tables = true
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multitarget accuracy</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL234-L265">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.BalancedAccuracy" href="#StatisticalMeasures.BalancedAccuracy"><code>StatisticalMeasures.BalancedAccuracy</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">BalancedAccuracy(; adjusted=false)</code></pre><p>Return a callable measure for computing the balanced accuracy. Aliases: <code>balanced_accuracy</code>, <code>bacc</code>, <code>bac</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>BalancedAccuracy</code> constructor (e.g., <code>m = BalancedAccuracy()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. This is a variation of <a href="#StatisticalMeasures.Accuracy"><code>Accuracy</code></a> compensating for class imbalance. See <a href="https://en.wikipedia.org/wiki/Precision_and_recall#Imbalanced_data">https://en.wikipedia.org/wiki/Precision<em>and</em>recall#Imbalanced_data</a>.</p><p>Setting <code>adjusted=true</code> rescales the score in the way prescribed in <a href="https://lib.dr.iastate.edu/etd/13537/">L. Mosley (2013)</a>: A balanced approach to the multi-class imbalance problem. PhD thesis, Iowa State University. In the binary case, the adjusted balanced accuracy is also known as <em>Youden’s J statistic</em>, or <em>informedness</em>.</p><p>This metric is invariant to class reordering.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = balanced accuracy</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL314-L348">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.Kappa" href="#StatisticalMeasures.Kappa"><code>StatisticalMeasures.Kappa</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">Kappa()</code></pre><p>Return a callable measure for computing the Cohen&#39;s κ. Aliases: <code>kappa</code>.</p><pre><code class="nohighlight hljs">Kappa()(ŷ, y)
Kappa()(ŷ, y, weights)</code></pre><p>Evaluate <code>Kappa()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. For details, see the <a href="https://en.wikipedia.org/wiki/Cohen%27s_kappa">Cohen&#39;s κ</a> Wikipedia article. Can also be called on confusion matrices. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>This metric is invariant to class reordering.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). </p><p>See also <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>. </p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.kappa-Tuple{Any}"><code>Functions.kappa</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = Cohen&#39;s κ</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL375-L409">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MatthewsCorrelation" href="#StatisticalMeasures.MatthewsCorrelation"><code>StatisticalMeasures.MatthewsCorrelation</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MatthewsCorrelation()</code></pre><p>Return a callable measure for computing the Matthew&#39;s correlation. Aliases: <code>matthews_correlation</code>, <code>mcc</code>.</p><pre><code class="nohighlight hljs">MatthewsCorrelation()(ŷ, y)</code></pre><p>Evaluate <code>MatthewsCorrelation()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. See the <a href="https://en.wikipedia.org/wiki/Matthews_correlation_coefficient">Wikipedia <em>Matthew&#39;s Correlation</em> page</a>. Can also be called on confusion matrices.  See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>This metric is invariant to class reordering.</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Finite,Missing}</code> (multiclass classification). </p><p>See also <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.matthews_correlation-Tuple{Any}"><code>Functions.matthews_correlation</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = Matthew&#39;s correlation</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL433-L467">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.FScore" href="#StatisticalMeasures.FScore"><code>StatisticalMeasures.FScore</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FScore(; beta=1.0, levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the <span>$F_β$</span> score. Aliases: <code>f1score</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>FScore</code> constructor (e.g., <code>m = FScore()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. This is the one-parameter generalization, <span>$F_β$</span>, of the <span>$F$</span>-measure or balanced <span>$F$</span>-score. Choose <code>beta=β</code> in the range <span>$[0,∞]$</span>, using <code>beta &gt; 1</code> to emphasize recall (<a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a>) over precision (<a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a>). When <code>beta = 1</code>, the score is the harmonic mean of precision and recall. See the <a href="https://en.wikipedia.org/wiki/F-score"><em>F1 score</em> Wikipedia page</a> for details.</p><p>If ordering classes (levels) on the basis of the eltype of <code>y</code>, then the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>FScore</code> mesaures can also be called on a confusion matrix.  See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.fscore"><code>Functions.fscore</code></a> </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = ``F_β`` score</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL545-L604">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.TruePositive" href="#StatisticalMeasures.TruePositive"><code>StatisticalMeasures.TruePositive</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">TruePositive(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the true positive count. Aliases: <code>true_positive</code>, <code>truepositive</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>TruePositive</code> constructor (e.g., <code>m = TruePositive()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassTruePositive"><code>MulticlassTruePositive</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.true_positive-Tuple{Any}"><code>Functions.true_positive</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = true positive count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.TrueNegative" href="#StatisticalMeasures.TrueNegative"><code>StatisticalMeasures.TrueNegative</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">TrueNegative(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the true negative count. Aliases: <code>true_negative</code>, <code>truenegative</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>TrueNegative</code> constructor (e.g., <code>m = TrueNegative()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassTrueNegative"><code>MulticlassTrueNegative</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.true_negative-Tuple{Any}"><code>Functions.true_negative</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = true negative count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.FalsePositive" href="#StatisticalMeasures.FalsePositive"><code>StatisticalMeasures.FalsePositive</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FalsePositive(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the false positive count. Aliases: <code>false_positive</code>, <code>falsepositive</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>FalsePositive</code> constructor (e.g., <code>m = FalsePositive()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassFalsePositive"><code>MulticlassFalsePositive</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.false_positive-Tuple{Any}"><code>Functions.false_positive</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = false positive count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.FalseNegative" href="#StatisticalMeasures.FalseNegative"><code>StatisticalMeasures.FalseNegative</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FalseNegative(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the false negative count. Aliases: <code>false_negative</code>, <code>falsenegative</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>FalseNegative</code> constructor (e.g., <code>m = FalseNegative()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassFalseNegative"><code>MulticlassFalseNegative</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.false_negative-Tuple{Any}"><code>Functions.false_negative</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = false negative count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.TruePositiveRate" href="#StatisticalMeasures.TruePositiveRate"><code>StatisticalMeasures.TruePositiveRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">TruePositiveRate(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the true positive rate. Aliases: <code>true_positive_rate</code>, <code>truepositive_rate</code>, <code>tpr</code>, <code>sensitivity</code>, <code>recall</code>, <code>hit_rate</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>TruePositiveRate</code> constructor (e.g., <code>m = TruePositiveRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>MulticlassTruePositiveRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.true_positive_rate-Tuple{Any}"><code>Functions.true_positive_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = true positive rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.TrueNegativeRate" href="#StatisticalMeasures.TrueNegativeRate"><code>StatisticalMeasures.TrueNegativeRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">TrueNegativeRate(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the true negative rate. Aliases: <code>true_negative_rate</code>, <code>truenegative_rate</code>, <code>tnr</code>, <code>specificity</code>, <code>selectivity</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>TrueNegativeRate</code> constructor (e.g., <code>m = TrueNegativeRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>MulticlassTrueNegativeRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.true_negative_rate-Tuple{Any}"><code>Functions.true_negative_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = true negative rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.FalsePositiveRate" href="#StatisticalMeasures.FalsePositiveRate"><code>StatisticalMeasures.FalsePositiveRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FalsePositiveRate(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the false positive rate. Aliases: <code>false_positive_rate</code>, <code>falsepositive_rate</code>, <code>fpr</code>, <code>fallout</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>FalsePositiveRate</code> constructor (e.g., <code>m = FalsePositiveRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassFalsePositiveRate"><code>MulticlassFalsePositiveRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.false_positive_rate-Tuple{Any}"><code>Functions.false_positive_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = false positive rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.FalseNegativeRate" href="#StatisticalMeasures.FalseNegativeRate"><code>StatisticalMeasures.FalseNegativeRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FalseNegativeRate(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the false negative rate. Aliases: <code>false_negative_rate</code>, <code>falsenegative_rate</code>, <code>fnr</code>, <code>miss_rate</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>FalseNegativeRate</code> constructor (e.g., <code>m = FalseNegativeRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassFalseNegativeRate"><code>MulticlassFalseNegativeRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.false_negative_rate-Tuple{Any}"><code>Functions.false_negative_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = false negative rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.FalseDiscoveryRate" href="#StatisticalMeasures.FalseDiscoveryRate"><code>StatisticalMeasures.FalseDiscoveryRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">FalseDiscoveryRate(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the false discovery rate. Aliases: <code>false_discovery_rate</code>, <code>falsediscovery_rate</code>, <code>fdr</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>FalseDiscoveryRate</code> constructor (e.g., <code>m = FalseDiscoveryRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassFalseDiscoveryRate"><code>MulticlassFalseDiscoveryRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.false_discovery_rate-Tuple{Any}"><code>Functions.false_discovery_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = false discovery rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.PositivePredictiveValue" href="#StatisticalMeasures.PositivePredictiveValue"><code>StatisticalMeasures.PositivePredictiveValue</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">PositivePredictiveValue(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the positive predictive value. Aliases: <code>positive_predictive_value</code>, <code>ppv</code>, <code>positivepredictive_value</code>, <code>precision</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>PositivePredictiveValue</code> constructor (e.g., <code>m = PositivePredictiveValue()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassPositivePredictiveValue"><code>MulticlassPositivePredictiveValue</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.positive_predictive_value-Tuple{Any}"><code>Functions.positive_predictive_value</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = positive predictive value</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.NegativePredictiveValue" href="#StatisticalMeasures.NegativePredictiveValue"><code>StatisticalMeasures.NegativePredictiveValue</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">NegativePredictiveValue(; levels=nothing, rev=nothing, checks=true)</code></pre><p>Return a callable measure for computing the negative predictive value. Aliases: <code>negative_predictive_value</code>, <code>negativepredictive_value</code>, <code>npv</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>NegativePredictiveValue</code> constructor (e.g., <code>m = NegativePredictiveValue()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. When ordering classes (levels) on the basis of the eltype of <code>y</code>, the <em>second</em> level is the &quot;positive&quot; class. To reverse roles, specify <code>rev=true</code>.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix. See <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p><strong>Keyword options</strong></p><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p>See also <a href="#StatisticalMeasures.MulticlassNegativePredictiveValue"><code>MulticlassNegativePredictiveValue</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.negative_predictive_value-Tuple{Any}"><code>Functions.negative_predictive_value</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = negative predictive value</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL732-L786">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassTruePositive" href="#StatisticalMeasures.MulticlassTruePositive"><code>StatisticalMeasures.MulticlassTruePositive</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassTruePositive(; levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class true positive count. Aliases: <code>multiclass_true_positive</code>, <code>multiclass_truepositive</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassTruePositive</code> constructor (e.g., <code>m = MulticlassTruePositive()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is a one-versus-rest version of the binary measure <a href="#StatisticalMeasures.TruePositive"><code>TruePositive</code></a>, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix.  Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.TruePositive"><code>TruePositive</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_true_positive-Tuple{Any}"><code>Functions.multiclass_true_positive</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = multi-class true positive count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL892-L964">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassTrueNegative" href="#StatisticalMeasures.MulticlassTrueNegative"><code>StatisticalMeasures.MulticlassTrueNegative</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassTrueNegative(; levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class true negative count. Aliases: <code>multiclass_true_negative</code>, <code>multiclass_truenegative</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassTrueNegative</code> constructor (e.g., <code>m = MulticlassTrueNegative()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is a one-versus-rest version of the binary measure <a href="#StatisticalMeasures.TrueNegative"><code>TrueNegative</code></a>, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix.  Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.TrueNegative"><code>TrueNegative</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_true_negative-Tuple{Any}"><code>Functions.multiclass_true_negative</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = multi-class true negative count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL892-L964">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassFalsePositive" href="#StatisticalMeasures.MulticlassFalsePositive"><code>StatisticalMeasures.MulticlassFalsePositive</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassFalsePositive(; levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class false positive count. Aliases: <code>multiclass_false_positive</code>, <code>multiclass_falsepositive</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassFalsePositive</code> constructor (e.g., <code>m = MulticlassFalsePositive()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is a one-versus-rest version of the binary measure <a href="#StatisticalMeasures.FalsePositive"><code>FalsePositive</code></a>, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix.  Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.FalsePositive"><code>FalsePositive</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_false_positive-Tuple{Any}"><code>Functions.multiclass_false_positive</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = multi-class false positive count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL892-L964">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassFalseNegative" href="#StatisticalMeasures.MulticlassFalseNegative"><code>StatisticalMeasures.MulticlassFalseNegative</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassFalseNegative(; levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class false negative count. Aliases: <code>multiclass_false_negative</code>, <code>multiclass_falsenegative</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassFalseNegative</code> constructor (e.g., <code>m = MulticlassFalseNegative()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is a one-versus-rest version of the binary measure <a href="#StatisticalMeasures.FalseNegative"><code>FalseNegative</code></a>, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p><code>m</code> can also be called on a confusion matrix.  Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.FalseNegative"><code>FalseNegative</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_false_negative-Tuple{Any}"><code>Functions.multiclass_false_negative</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Sum()
human_name = multi-class false negative count</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL892-L964">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassTruePositiveRate" href="#StatisticalMeasures.MulticlassTruePositiveRate"><code>StatisticalMeasures.MulticlassTruePositiveRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassTruePositiveRate(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class true positive rate. Aliases: <code>multiclass_true_positive_rate</code>, <code>multiclass_truepositive_rate</code>, <code>multiclass_tpr</code>, <code>multiclass_sensitivity</code>, <code>multiclass_recall</code>, <code>multiclass_hit_rate</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassTruePositiveRate</code> constructor (e.g., <code>m = MulticlassTruePositiveRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.TruePositiveRate"><code>TruePositiveRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_true_positive_rate-Tuple{Any, Any, Vararg{Any}}"><code>Functions.multiclass_true_positive_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class true positive rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1132-L1209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassTrueNegativeRate" href="#StatisticalMeasures.MulticlassTrueNegativeRate"><code>StatisticalMeasures.MulticlassTrueNegativeRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassTrueNegativeRate(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class true negative rate. Aliases: <code>multiclass_true_negative_rate</code>, <code>multiclass_truenegative_rate</code>, <code>multiclass_tnr</code>, <code>multiclass_specificity</code>, <code>multiclass_selectivity</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassTrueNegativeRate</code> constructor (e.g., <code>m = MulticlassTrueNegativeRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.TrueNegativeRate"><code>TrueNegativeRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_true_negative_rate-Tuple{Any, Any, Vararg{Any}}"><code>Functions.multiclass_true_negative_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class true negative rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1132-L1209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassFalsePositiveRate" href="#StatisticalMeasures.MulticlassFalsePositiveRate"><code>StatisticalMeasures.MulticlassFalsePositiveRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassFalsePositiveRate(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class false positive rate. Aliases: <code>multiclass_false_positive_rate</code>, <code>multiclass_falsepositive_rate</code>, <code>multiclass_fpr</code>, <code>multiclass_fallout</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassFalsePositiveRate</code> constructor (e.g., <code>m = MulticlassFalsePositiveRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.FalsePositiveRate"><code>FalsePositiveRate</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.FalsePositiveRate"><code>FalsePositiveRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_false_positive_rate-Tuple{Any, Any, Vararg{Any}}"><code>Functions.multiclass_false_positive_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class false positive rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1132-L1209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassFalseNegativeRate" href="#StatisticalMeasures.MulticlassFalseNegativeRate"><code>StatisticalMeasures.MulticlassFalseNegativeRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassFalseNegativeRate(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class false negative rate. Aliases: <code>multiclass_false_negative_rate</code>, <code>multiclass_falsenegative_rate</code>, <code>multiclass_fnr</code>, <code>multiclass_miss_rate</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassFalseNegativeRate</code> constructor (e.g., <code>m = MulticlassFalseNegativeRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.FalseNegativeRate"><code>FalseNegativeRate</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.FalseNegativeRate"><code>FalseNegativeRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_false_negative_rate-Tuple{Any, Any, Vararg{Any}}"><code>Functions.multiclass_false_negative_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class false negative rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1132-L1209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassFalseDiscoveryRate" href="#StatisticalMeasures.MulticlassFalseDiscoveryRate"><code>StatisticalMeasures.MulticlassFalseDiscoveryRate</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassFalseDiscoveryRate(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class false discovery rate. Aliases: <code>multiclass_false_discovery_rate</code>, <code>multiclass_falsediscovery_rate</code>, <code>multiclass_fdr</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassFalseDiscoveryRate</code> constructor (e.g., <code>m = MulticlassFalseDiscoveryRate()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.FalseDiscoveryRate"><code>FalseDiscoveryRate</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.FalseDiscoveryRate"><code>FalseDiscoveryRate</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_false_discovery_rate-Tuple{Any, Any, Vararg{Any}}"><code>Functions.multiclass_false_discovery_rate</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class false discovery rate</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1132-L1209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassPositivePredictiveValue" href="#StatisticalMeasures.MulticlassPositivePredictiveValue"><code>StatisticalMeasures.MulticlassPositivePredictiveValue</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassPositivePredictiveValue(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class positive predictive value. Aliases: <code>multiclass_positive_predictive_value</code>, <code>multiclass_ppv</code>, <code>multiclass_positivepredictive_value</code>, <code>multiclass_precision</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassPositivePredictiveValue</code> constructor (e.g., <code>m = MulticlassPositivePredictiveValue()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.PositivePredictiveValue"><code>PositivePredictiveValue</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_positive_predictive_value-Tuple{Any, Any, Vararg{Any}}"><code>Functions.multiclass_positive_predictive_value</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class positive predictive value</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1132-L1209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassNegativePredictiveValue" href="#StatisticalMeasures.MulticlassNegativePredictiveValue"><code>StatisticalMeasures.MulticlassNegativePredictiveValue</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassNegativePredictiveValue(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class negative predictive value. Aliases: <code>multiclass_negative_predictive_value</code>, <code>multiclass_negativepredictive_value</code>, <code>multiclass_npv</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassNegativePredictiveValue</code> constructor (e.g., <code>m = MulticlassNegativePredictiveValue()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.NegativePredictiveValue"><code>NegativePredictiveValue</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.NegativePredictiveValue"><code>NegativePredictiveValue</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_negative_predictive_value-Tuple{Any, Any, Vararg{Any}}"><code>Functions.multiclass_negative_predictive_value</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class negative predictive value</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1132-L1209">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.MulticlassFScore" href="#StatisticalMeasures.MulticlassFScore"><code>StatisticalMeasures.MulticlassFScore</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">MulticlassFScore(; average=macro_avg, levels=nothing, more_options...)</code></pre><p>Return a callable measure for computing the multi-class <span>$F_β$</span> score. Aliases: <code>macro_f1score</code>, <code>micro_f1score</code>, <code>multiclass_f1score</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>MulticlassFScore</code> constructor (e.g., <code>m = MulticlassFScore()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. </p><p>This is an averaged one-versus-rest version of the binary <a href="#StatisticalMeasures.FScore"><code>FScore</code></a>. Or it can return a dictionary keyed on target class (or a vector); see <code>average</code> options below.</p><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>You can also call <code>m</code> on confusion matrices. Construct confusion matrices using <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{OrderedFactor{2},Missing}</code> (binary classification where definition of &quot;positive&quot; class matters). </p><p><strong>Keyword options</strong></p><ul><li><code>beta=1.0</code>: parameter in the range <span>$[0,∞]$</span>, emphasizing recall over precision for <code>beta &gt; 1</code>, except in the case <code>average=MicroAvg()</code>, when it has no effect.</li></ul><ul><li><code>average=MacroAvg()</code>: one of: <code>NoAvg()</code>, <code>MacroAvg()</code>, <code>MicroAvg()</code> (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst <a href="https://arxiv.org/abs/1911.03347">(2019)</a>. &quot;Macro F1 and Macro F1&quot;, <em>arXiv</em>.</li></ul><ul><li><code>return_type=LittleDict</code>: type of returned measurement for <code>average=NoAvg()</code> case; if <code>LittleDict</code>, then keyed on levels of the target; can also be <code>Vector</code></li></ul><ul><li><p><code>levels::Union{Vector,Nothing}=nothing</code>: if <code>nothing</code>, levels are inferred from  <code>ŷ</code> and <code>y</code> and, by default, ordered according to the element type of <code>y</code>.</p></li><li><p><code>rev=false</code>: in the case of binary data, whether to reverse the <code>levels</code> (as inferred or specified); a <code>nothing</code> value is the same as <code>false</code>.</p></li></ul><ul><li><code>perm=nothing</code>: in the general case, a permutation representing a re-ordering of <code>levels</code> (as inferred or specified); e.g., <code>perm = [1,3,2]</code> for data with three classes.</li></ul><ul><li><code>checks=true</code>: when true, specified <code>levels</code> are checked to see they include all observed levels; set to <code>false</code> for speed.</li></ul><p>Method is optimized for <code>CategoricalArray</code> inputs with <code>levels</code> inferred. In that case <code>levels</code> will be the complete internal class pool, and not just the observed levels.</p><p>See also <a href="#StatisticalMeasures.FScore"><code>FScore</code></a>, <a href="../confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix"><code>StatisticalMeasures.ConfusionMatrices.ConfusionMatrix</code></a> and <a href="#StatisticalMeasures.ConfusionMatrix"><code>ConfusionMatrix</code></a>.</p><p>Core algorithm: <a href="../reference/#StatisticalMeasures.Functions.multiclass_fscore-Tuple{Any, Any, MicroAvg}"><code>Functions.multiclass_fscore</code></a></p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.LiteralTarget()
observation_scitype = Union{Missing, ScientificTypesBase.Multiclass}
can_consume_tables = false
supports_weights = false
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = multi-class ``F_β`` score</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/finite.jl#LL1355-L1436">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.AreaUnderCurve" href="#StatisticalMeasures.AreaUnderCurve"><code>StatisticalMeasures.AreaUnderCurve</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">AreaUnderCurve()</code></pre><p>Return a callable measure for computing the area under the receiver operator characteritic. Aliases: <code>auc</code>, <code>area_under_curve</code>.</p><pre><code class="nohighlight hljs">AreaUnderCurve()(ŷ, y)</code></pre><p>Evaluate <code>AreaUnderCurve()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. See the <a href="https://en.wikipedia.org/wiki/Receiver_operating_characteristic"><em>Recevier operator chararacteristic</em></a> (ROC) Wikipedia article for a definition. It is expected that <code>ŷ</code> be a vector of distributions over the binary set of unique elements of <code>y</code>; specifically, <code>ŷ</code> should have eltype <code>&lt;:UnivariateFinite</code> from the CategoricalDistributions.jl package.</p><p>Implementation is based on the Mann-Whitney U statistic.  See the <a href="https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test#Area_under_curve_(AUC)_statistic_for_ROC_curves"><em>Whitney U test</em></a> Wikipedia page for details. </p><p>Core implementation: <a href="../reference/#StatisticalMeasures.Functions.auc-Tuple{Any, Any, Any}"><code>Functions.auc</code></a>.</p><p>This metric is invariant to class reordering.</p><p>Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>ScientificTypesBase.Binary</code>. </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.Distribution()
observation_scitype = ScientificTypesBase.Binary
can_consume_tables = false
supports_weights = false
supports_class_weights = false
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = area under the receiver operator characteritic</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/probabilistic.jl#LL109-L144">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.LogScore" href="#StatisticalMeasures.LogScore"><code>StatisticalMeasures.LogScore</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LogScore(; tol=eps())</code></pre><p>Return a callable measure for computing the log score. Aliases: <code>log_score</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>LogScore</code> constructor (e.g., <code>m = LogScore()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. The score is a mean of observational scores. More generally, observational scores are pre-multiplied by the specified weights before avaraging. See below for the form that probabilistic predictions <code>ŷ</code> should take. Raw probabilities are clamped away from <code>0</code> and <code>1</code>. Specifically, if <code>p</code> is the probability mass/density function evaluated at given observed ground truth observation <code>η</code>, then the score for that example is defined as</p><pre><code class="nohighlight hljs">log(clamp(p(η), tol, 1 - tol).</code></pre><p>For example, for a binary target with &quot;yes&quot;/&quot;no&quot; labels, if the probabilistic prediction scores 0.8 for a &quot;yes&quot;, then for a corresponding ground truth observation of &quot;no&quot;, that example&#39;s contribution to the score is <code>log(0.2)</code>.</p><p>The predictions <code>ŷ</code> should be a vector of <code>UnivariateFinite</code> distributions from CategoricalDistritutions.jl, in the case of <code>Finite</code> target <code>y</code> (a <code>CategoricalVector</code>) and should otherwise be a supported <code>Distributions.UnivariateDistribution</code> such as <code>Normal</code> or <code>Poisson</code>.</p><p>See also <a href="#StatisticalMeasures.LogLoss"><code>LogLoss</code></a>, which differs only in sign.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Missing,T}</code> where <code>T</code> is <code>Continuous</code> or <code>Count</code> (for respectively continuous or discrete Distribution.jl objects in <code>ŷ</code>) or  <code>OrderedFactor</code> or <code>Multiclass</code> (for <code>UnivariateFinite</code> distributions in <code>ŷ</code>). </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.Distribution()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = log score</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/probabilistic.jl#LL201-L248">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.LogLoss" href="#StatisticalMeasures.LogLoss"><code>StatisticalMeasures.LogLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">LogLoss(; tol=eps())</code></pre><p>Return a callable measure for computing the log loss. Aliases: <code>log_loss</code>, <code>cross_entropy</code>.</p><pre><code class="nohighlight hljs">m(ŷ, y)
m(ŷ, y, weights)
m(ŷ, y, class_weights::AbstractDict)
m(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate some measure <code>m</code> returned by the <code>LogLoss</code> constructor (e.g., <code>m = LogLoss()</code>) on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. For details, see <a href="#StatisticalMeasures.LogScore"><code>LogScore</code></a>, which differs only by a sign.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Missing,T}</code> where <code>T</code> is <code>Continuous</code> or <code>Count</code> (for respectively continuous or discrete Distribution.jl objects in <code>ŷ</code>) or  <code>OrderedFactor</code> or <code>Multiclass</code> (for <code>UnivariateFinite</code> distributions in <code>ŷ</code>). </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.Distribution()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = log loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/probabilistic.jl#LL250-L278">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.BrierScore" href="#StatisticalMeasures.BrierScore"><code>StatisticalMeasures.BrierScore</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">BrierScore()</code></pre><p>Return a callable measure for computing the brier score. Aliases: <code>brier_score</code>, <code>quadratic_score</code>.</p><pre><code class="nohighlight hljs">BrierScore()(ŷ, y)
BrierScore()(ŷ, y, weights)
BrierScore()(ŷ, y, class_weights::AbstractDict)
BrierScore()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>BrierScore()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. The score is a mean of observational scores. More generally, observational scores are pre-multiplied by the specified weights before avaraging. See below for the form that probabilistic predictions <code>ŷ</code> should take.</p><p>Convention as in Gneiting and Raftery <a href="https://doi.org/10.1198/016214506000001437">(2007)</a>, &quot;StrictlyProper Scoring Rules, Prediction, and Estimation&quot;</p><p><em>Finite case.</em> If <code>p(η)</code> is the predicted probability for a <em>single</em> observation <code>η</code>, and <code>C</code> all possible classes, then the corresponding score for that example is given by</p><p><span>$2p(η) - \left(\sum_{c ∈ C} p(c)^2\right) - 1$</span></p><p><em>Warning.</em> <code>BrierScore()</code> is a &quot;score&quot; in the sense that bigger is better (with <code>0</code> optimal, and all other values negative). In Brier&#39;s original 1950 paper, and many other places, it has the opposite sign, despite the name. Moreover, the present implementation does not treat the binary case as special, so that the score may differ in the binary case by a factor of two from usage elsewhere.</p><p><em>Infinite case.</em> Replacing the sum above with an integral does <em>not</em> lead to the formula adopted here in the case of <code>Continuous</code> or <code>Count</code> target <code>y</code>. Rather the convention in the paper cited above is adopted, which means returning a score of</p><p><span>$2p(η) - ∫ p(t)^2 dt$</span></p><p>in the <code>Continuous</code> case (<code>p</code> the probablity density function) or</p><p><span>$2p(η) - ∑_t p(t)^2$</span></p><p>in the <code>Count</code> case (<code>p</code> the probablity mass function).</p><p>The predictions <code>ŷ</code> should be a vector of <code>UnivariateFinite</code> distributions from CategoricalDistritutions.jl, in the case of <code>Finite</code> target <code>y</code> (a <code>CategoricalVector</code>) and should otherwise be a supported <code>Distributions.UnivariateDistribution</code> such as <code>Normal</code> or <code>Poisson</code>.</p><p>See also <a href="#StatisticalMeasures.BrierLoss"><code>BrierLoss</code></a>, which differs only in sign.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Missing,T}</code> where <code>T</code> is <code>Continuous</code> or <code>Count</code> (for respectively continuous or discrete Distribution.jl objects in <code>ŷ</code>) or  <code>OrderedFactor</code> or <code>Multiclass</code> (for <code>UnivariateFinite</code> distributions in <code>ŷ</code>). </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.Distribution()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = brier score</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/probabilistic.jl#LL371-L438">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.BrierLoss" href="#StatisticalMeasures.BrierLoss"><code>StatisticalMeasures.BrierLoss</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">BrierLoss()</code></pre><p>Return a callable measure for computing the brier loss. Aliases: <code>brier_loss</code>, <code>cross_entropy</code>, <code>quadratic_loss</code>.</p><pre><code class="nohighlight hljs">BrierLoss()(ŷ, y)
BrierLoss()(ŷ, y, weights)
BrierLoss()(ŷ, y, class_weights::AbstractDict)
BrierLoss()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>BrierLoss()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. For details, see <a href="#StatisticalMeasures.BrierScore"><code>BrierScore</code></a>, which differs only by a sign.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Missing,T}</code> where <code>T</code> is <code>Continuous</code> or <code>Count</code> (for respectively continuous or discrete Distribution.jl objects in <code>ŷ</code>) or  <code>OrderedFactor</code> or <code>Multiclass</code> (for <code>UnivariateFinite</code> distributions in <code>ŷ</code>). </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = false
kind_of_proxy = LearnAPI.Distribution()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Loss()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = brier loss</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/probabilistic.jl#LL420-L448">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatisticalMeasures.SphericalScore" href="#StatisticalMeasures.SphericalScore"><code>StatisticalMeasures.SphericalScore</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">SphericalScore()</code></pre><p>Return a callable measure for computing the spherical score. Aliases: <code>spherical_score</code>.</p><pre><code class="nohighlight hljs">SphericalScore()(ŷ, y)
SphericalScore()(ŷ, y, weights)
SphericalScore()(ŷ, y, class_weights::AbstractDict)
SphericalScore()(ŷ, y, weights, class_weights::AbstractDict)</code></pre><p>Evaluate <code>SphericalScore()</code> on predictions <code>ŷ</code>, given ground truth observations <code>y</code>. The score is a mean of observational scores. More generally, observational scores are pre-multiplied by the specified weights before avaraging. See below for the form that probabilistic predictions <code>ŷ</code> should take.</p><p>Convention as in Gneiting and Raftery <a href="https://doi.org/10.1198/016214506000001437">(2007)</a>, &quot;StrictlyProper Scoring Rules, Prediction, and Estimation&quot;: If <code>y</code> takes on a finite number of classes <code>C</code> and <code>p(y)</code> is the predicted probability for a single observation <code>y</code>, then the corresponding score for that example is given by</p><p><span>$p(y)^α / \left(\sum_{η ∈ C} p(η)^α\right)^{1-α} - 1$</span></p><p>where <code>α</code> is the measure parameter <code>alpha</code>.</p><p>In the case the predictions <code>ŷ</code> are continuous probability distributions, such as <code>Distributions.Normal</code>, replace the above sum with an integral, and interpret <code>p</code> as the probablity density function. In case of discrete distributions over the integers, such as <code>Distributions.Poisson</code>, sum over all integers instead of <code>C</code>.</p><p>Any iterator with a <code>length</code> generating <code>Real</code> elements can be used for <code>weights</code>. The keys of <code>class_weights</code> should include all conceivable values for observations in <code>y</code>, and values should be <code>Real</code>. </p><p>Measurements are aggregated. To obtain a separate measurement for each observation, use the syntax <code>measurements(m, ŷ, y)</code>. Generally, an observation <code>obs</code> in <code>MLUtils.eachobs(y)</code> is expected to satisfy <code>ScientificTypes.scitype(obs)&lt;:</code><code>Union{Missing,T}</code> where <code>T</code> is <code>Continuous</code> or <code>Count</code> (for respectively continuous or discrete Distribution.jl objects in <code>ŷ</code>) or  <code>OrderedFactor</code> or <code>Multiclass</code> (for <code>UnivariateFinite</code> distributions in <code>ŷ</code>). </p><p>For a complete dictionary of available measures, keyed on constructor, run <a href="../tools/#StatisticalMeasures.measures"><code>measures()</code></a>. </p><p><strong>Traits</strong></p><pre><code class="nohighlight hljs">consumes_multiple_observations = true
can_report_unaggregated = true
kind_of_proxy = LearnAPI.Distribution()
observation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}
can_consume_tables = false
supports_weights = true
supports_class_weights = true
orientation = StatisticalMeasuresBase.Score()
external_aggregation_mode = StatisticalMeasuresBase.Mean()
human_name = spherical score</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/StatisticalMeasures.jl/blob/6e2676ff7bdb19a3250ede050f8457cb574dd660/src/probabilistic.jl#LL532-L580">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples_of_usage/">« Examples of usage</a><a class="docs-footer-nextpage" href="../confusion_matrices/">Confusion Matrices »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Sunday 21 May 2023 22:53">Sunday 21 May 2023</span>. Using Julia version 1.9.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
