var documenterSearchIndex = {"docs":
[{"location":"roc/#Receiver-Operator-Characteristics","page":"Receiver Operator Characteristics","title":"Receiver Operator Characteristics","text":"","category":"section"},{"location":"roc/#Example","page":"Receiver Operator Characteristics","title":"Example","text":"","category":"section"},{"location":"roc/","page":"Receiver Operator Characteristics","title":"Receiver Operator Characteristics","text":"using StatisticalMeasures\nusing CategoricalArrays\nusing CategoricalDistributions\n\n# ground truth:\ny = categorical([\"X\", \"O\", \"X\", \"X\", \"O\", \"X\", \"X\", \"O\", \"O\", \"X\"], ordered=true)\n\n# probabilistic predictions:\nX_probs = [0.3, 0.2, 0.4, 0.9, 0.1, 0.4, 0.5, 0.2, 0.8, 0.7]\nŷ = UnivariateFinite([\"O\", \"X\"], X_probs, augment=true, pool=y)\nŷ[1]","category":"page"},{"location":"roc/","page":"Receiver Operator Characteristics","title":"Receiver Operator Characteristics","text":"using Plots\ncurve = roc_curve(ŷ, y)\nplt = plot(curve, legend=false)\nplot!(plt, xlab=\"false positive rate\", ylab=\"true positive rate\")\nplot!([0, 1], [0, 1], linewidth=2, linestyle=:dash, color=:black)","category":"page"},{"location":"roc/","page":"Receiver Operator Characteristics","title":"Receiver Operator Characteristics","text":"(Image: )","category":"page"},{"location":"roc/","page":"Receiver Operator Characteristics","title":"Receiver Operator Characteristics","text":"auc(ŷ, y) # maximum possible is 1.0","category":"page"},{"location":"roc/#Reference","page":"Receiver Operator Characteristics","title":"Reference","text":"","category":"section"},{"location":"roc/","page":"Receiver Operator Characteristics","title":"Receiver Operator Characteristics","text":"roc_curve","category":"page"},{"location":"roc/#StatisticalMeasures.roc_curve","page":"Receiver Operator Characteristics","title":"StatisticalMeasures.roc_curve","text":"roc_curve(ŷ, y) -> false_positive_rates, true_positive_rates, thresholds\n\nReturn data for plotting the receiver operator characteristic (ROC curve) for a binary classification problem.\n\nHere ŷ is a vector of UnivariateFinite distributions (from CategoricalDistributions.jl) over the two values taken by the ground truth observations y, a CategoricalVector. \n\nIf there are k unique probabilities, then there are correspondingly k thresholds and k+1 \"bins\" over which the false positive and true positive rates are constant.:\n\n[0.0 - thresholds[1]]\n[thresholds[1] - thresholds[2]]\n...\n[thresholds[k] - 1]\n\nConsequently, true_positive_rates and false_positive_rates have length k+1 if thresholds has length k.\n\nTo plot the curve using your favorite plotting backend, do something like plot(false_positive_rates, true_positive_rates).\n\nCore algorithm: Functions.roc_curve\n\nSee also AreaUnderCurve. \n\n\n\n\n\n","category":"function"},{"location":"tools/#Tools","page":"Tools","title":"Tools","text":"","category":"section"},{"location":"tools/","page":"Tools","title":"Tools","text":"method description\nmeasurements(measure, ...) for obtaining per-observation measurements, instead of aggregated ones\nmeasures() dictionary of traits keyed on measure constructors, with filter options\nunfussy(measure) new measure without argument checks¹\nmultimeasure(measure; options...) wrapper to broadcast measures over multiple observations\nrobust_measure(measure) wrapper to silently treat unsupported weights as uniform\nMeasure(measure) wrapper for 3rd party measures with different calling syntax (e.g. LossFunctions.jl)","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"¹For measures provided by StatisticalMeasures; behaviour for general measures may differ.","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"For more on defining your own measures, see the StatisticalMeasuresBase.jl documentation.","category":"page"},{"location":"tools/","page":"Tools","title":"Tools","text":"measurements\nmeasures\nunfussy\nmultimeasure\nrobust_measure\nMeasure","category":"page"},{"location":"tools/#StatisticalMeasuresBase.measurements","page":"Tools","title":"StatisticalMeasuresBase.measurements","text":"measurements(measure, ŷ, y[, weights, class_weights::AbstractDict])\n\nReturn a vector of measurements, one for each observation in y, rather than a single aggregated measurement. Otherwise the behavior is the same as calling the measure directly on data.\n\nNew implementations\n\nOverloading this function for new measure types is optional. A fallback returns the aggregated measure, repeated n times, where n = MLUtils.numobs(y) (which falls back to length(y) if numobs is not implemented).  It is not typically necessary to overload measurements for wrapped measures.  All multimeasures provide the obvious fallback and other wrappers simply forward the measurements method of the atomic measure. If overloading, use the following signatures:\n\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, y)\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, weights)\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, class_weights::AbstractDict)\nStatisticalMeasuresBase.measurements(measure::SomeMeasureType, ŷ, weights, class_weights)\n\n\n\n\n\n","category":"function"},{"location":"tools/#StatisticalMeasures.measures","page":"Tools","title":"StatisticalMeasures.measures","text":"measures(; trait_options...)\n\nExperimental and subject to breaking behavior between patch releases.\n\nReturn a dictionary, dict, keyed on measure constructors provided by StatisticalMeasures.jl. The value of dict[constructor] provides information about traits (measure \"metadata\") shared by all measures constructed using the syntax constructor(args...).\n\nTrait options\n\nOne can filter on the basis of measure trait values, as shown in this example:\n\nusing StatisticalMeasures\nimport ScientificTypesBase.Multiclass\n\njulia> measures(\n    observation_scitype = Union{Missing,Multiclass},\n    supports_class_weights = true,\n)\n\n\n\nmeasures(y; trait_filters...)\nmeasures(yhat, y; trait_filters...)\n\nExperimental and subject to breaking behavior between patch releases.\n\nAssuming, ScientificTypes.jl has been imported, find measures that can be applied to data with the specified data arguments (y,) or (yhat, y). It is assumed that the arguments contain multiple observations (have types implementing MLUtils.getobs).\n\nReturns a dictionary keyed on the constructors of such measures. Additional trait_filters are the same as for the zero argument measures method.\n\nusing StatisticalArrays\nusing ScientificTypes\n\njulia> measures(rand(3), rand(3), supports_weights=false)\nLittleDict{Any, Any, Vector{Any}, Vector{Any}} with 1 entry:\n  RSquared => (aliases = (\"rsq\", \"rsquared\"), consumes_multiple_observations = true, can_re…\n\nWarning. Matching is based only on the first observation of the arguments provided, and must be interpreted carefully if, for example, y or yhat are vectors with Union or other abstract element types.\n\n\n\n\n\nmeasures(needle::Union{AbstractString,Regex}; trait_options...)\n\nExperimental and subject to breaking behavior between patch releases.\n\nFind measures that contain needle in their document string.  Returns a dictionary keyed on the constructors of such measures.\n\njulia> measures(\"Matthew\")\nLittleDict{Any, Any, Vector{Any}, Vector{Any}} with 1 entry:\n  MatthewsCorrelation => (aliases = (\"matthews_correlation\", \"mcc\"), consumes_multiple_obse…\n\n\n\n\n\n","category":"function"},{"location":"tools/#StatisticalMeasuresBase.unfussy","page":"Tools","title":"StatisticalMeasuresBase.unfussy","text":"unfussy(measure)\n\nReturn a version of measure with argument checks removed, if that is possible. Specifically, if measure == fussy_measure(atomic_measure), for some atomic_measure, then return atomic_measure. Otherwise, return measure.\n\nSee also StatisticalMeasuresBase.fussy_measure.\n\n\n\n\n\n","category":"function"},{"location":"tools/#StatisticalMeasuresBase.multimeasure","page":"Tools","title":"StatisticalMeasuresBase.multimeasure","text":"StatisticalMeasuresBase.multimeasure(atomic_measure; options...)\n\nReturn a new measure, called a multi-measure, which, on a prediction-target pair (ŷ, y), broadcasts atomic_measure over MLUtils.eachobs((ŷ, y)) and aggregates the result. Here ŷ and y are necessarily objects implementing the MLUtils getobs/numobs interface, such as arrays, and tables X for which Tables.istable(X) == true.\n\nAll multi-measures automatically support weights and class weights.\n\nBy default, aggregation is performed using the preferred mode for atomic_measure, i.e., StatisticalMeasuresBase.external_aggregation_mode(atomic_measure). Internally, aggregation is performed using the aggregate method.\n\nNested applications of multimeasure are useful for building measures that apply to matrices and some tables (\"multi-targets\") as well as multidimensional arrays. See the Advanced Examples below.\n\nSimple example\n\nusing StatisticalMeasuresBase\n\n# define an atomic measure:\nstruct L2OnScalars\n(::L2OnScalars)(ŷ, y) = (ŷ - y)^2\n\njulia> StatisticalMeasuresBase.external_aggregation_mode(L2OnScalars())\nMean()\n\n# define a multimeasure:\nL2OnVectors() = StatisticalMeasuresBase.multimeasure(L2OnScalars())\n\ny = [1, 2, 3]\nŷ = [7, 6, 5]\n@assert L2OnVectors()(ŷ, y) ≈ (ŷ - y).^2 |> mean\n\nKeyword options\n\nmode=StatisticalMeasuresBase.external_aggregation_mode(atomic_measure): mode for aggregating the results of broadcasting. Possible values include Mean() and Sum(). See AggregationMode for all options and their meanings. Using Mean() in conjunction with weights returns the usual weighted mean scaled by the average weight value. .\ntransform=identity: an optional transformation applied to observations in y and ŷ before passing to each atomic_measure call. A useful value is vec∘collect which is the identity on vectors, flattens arrays, and converts the observations of some tables (it's \"rows\") to vectors. See the example below.\natomic_weights=nothing: the weights to be passed to the atomic measure, on each call to evaluate it on the pair (transform(ŷᵢ), transform(yᵢ)), for each (ŷᵢ, yᵢ) in MLUtils.eachjobs(ŷ, y). Assumes atomic_measure supports weights.\nskipnan=false: whether to skip NaN values when aggregating (missing values are always skipped)\n\nAdvanced examples\n\nBuilding on L2OnVectors defined above:\n\n# define measure for multi-dimensional arrays and some tables:\nL2() = multimeasure(L2OnVectors(), transform=vec∘collect)\n\ny = rand(3, 5, 100)\nŷ = rand(3, 5, 100)\nweights = rand(100)\n@assert L2()(ŷ, y, weights) ≈\n   sum(vec(mean((ŷ - y).^2, dims=[1, 2])).*weights)/length(weights)\n\nusing Tables\ny = rand(3, 100)\nŷ = rand(3, 100)\nt = Tables.table(y') |> Tables.rowtable\nt̂ = Tables.table(ŷ') |> Tables.rowtable\n@assert L2()(t̂, t, weights) ≈\n   sum(vec(mean((ŷ - y).^2, dims=1)).*weights)/length(weights)\n\nnote: Note\nThe measure traits StatisticalMeasuresBase.observation_scitype(measure) (default=Union{}) and StatisticalMeasuresBase.can_consume_tables(measure) (default=false) are not forwarded from the atomic measure and must be explicitly overloaded for measures wrapped using multimeasure.\n\n\n\n\n\n","category":"function"},{"location":"tools/#StatisticalMeasuresBase.robust_measure","page":"Tools","title":"StatisticalMeasuresBase.robust_measure","text":"robust_measure(measure)\n\nReturn a new measure robust such that:\n\nweights and class_weights are silently treated as uniform (unit) if unsupported by measure\nif either weights or class_weights is nothing, it is as if the argument is omitted (interpreted as uniform)\n\nThis holds for all calls of the form robust(ŷ, y, weights, class_weights) or measurements(robust, ŷ, y, weights, class_weights) and otherwise the behavior of robust is the same as for measure.\n\n\n\n\n\n","category":"function"},{"location":"tools/#StatisticalMeasuresBase.Measure","page":"Tools","title":"StatisticalMeasuresBase.Measure","text":"Measure(m)\n\nConvert a measure-like object m to a measure in the sense of StatisticalMeasuresBase.jl; see StatisticalMeasuresBase.is_measure for the definition.\n\nTypically, Measure is applied to measures with pre-existing calling behaviour different from that specified by StatisticalMeasuresBase.jl.\n\nNew implementations\n\nTo make a measure-like object of type M wrappable by Measure, implement the appropriate methods below. The first and last are compulsory.\n\n(m::Measure{M})(ŷ, y)\n(m::Measure{M})(ŷ, y, weights)\n(m::Measure{M})(ŷ, y, class_weights::AbstractDict)\n(m::Measure{M}, ŷ, y, weights, class_weights)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y, weights)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y, class_weights::AbstractDict)\nStatisticalMeasuresBase.measurements(m::Measure{M}, ŷ, y, weights, class_weights)\nStatisticalMeasuresBase.is_measure(m::Measure{M}) where M = true\n\nIn your implementations, you may use StatisticalMeasuresBase.unwrap to access the unwrapped object, i.e., StatisticalMeasuresBase.unwrap(Measure(m)) === m.\n\nSample implementation\n\nTo wrap the abs function as a measure that computes the absolute value of differences:\n\nimport StatisticalMeasuresBase as API\n\n(measure::API.Measure{typeof(abs)})(yhat, y) = API.unwrap(measure)(yhat - y)\nAPI.is_measure(::API.Measure{typeof(abs)}) = true\n\njulia> API.Measure(abs)(2, 5)\n3\n\n\n\n\n\n","category":"type"},{"location":"auto_generated_list_of_measures/#The-Measures","page":"The Measures","title":"The Measures","text":"","category":"section"},{"location":"auto_generated_list_of_measures/#Quick-links","page":"The Measures","title":"Quick links","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"List of aliases\nClassification measures (non-probabilistic)\nRegression measures (non-probabilistic)\nProbabilistic measures","category":"page"},{"location":"auto_generated_list_of_measures/#Scientific-type-of-observations","page":"The Measures","title":"Scientific type of observations","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"Measures can be classified according to the scientific type of the target observations they consume (given by the value of the trait, StatisticalMeasuresBase.observation_scitype(measure)):","category":"page"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"observation scitype meaning\nFinite general classification\nFinite{2}=Binary binary classification\nOrderedFactor classification (class order matters)\nOrderedFactor{2} binary classification (order matters)\nContinuous regression\nInfinite regression, including integer targets for Count data\nAbstractArray{T} multitarget version of T, some tabular data okay","category":"page"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"Measures are not strict about data conforming to the declared observation scitype. For example, where OrderedFactor{2} is expected, Finite{2} will work, and in fact most eltypes will work, so long as there are only two classes. However, you may get warnings that mitigate possible misinterpretations of results (e.g., about which class is the \"positive\" one). Some warnings can be suppressed by explicitly specifying measure parameters, such as levels.","category":"page"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"To be 100% safe and avoid warnings, use data with the recommended observation scitype.","category":"page"},{"location":"auto_generated_list_of_measures/#On-multi-target-measures-and-tabular-data","page":"The Measures","title":"On multi-target measures and tabular data","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"All multi-target measures below (the ones with AbstractArray observation scitypes) also handle some forms of tabular input, including DataFrames and Julia's native \"row table\" and \"column table\" formats. This is not reflected by the declared observation scitype. Instead, you can inspect the trait StatisticalMeasuresBase.can_consume_tables or consult the measure document string.","category":"page"},{"location":"auto_generated_list_of_measures/#Classification-measures-(non-probabilistic)","page":"The Measures","title":"Classification measures (non-probabilistic)","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"constructor / instance aliases observation scitype\nFScore Union{Missing, OrderedFactor{2}}\nFalseDiscoveryRate Union{Missing, OrderedFactor{2}}\nFalseNegative Union{Missing, OrderedFactor{2}}\nFalseNegativeRate Union{Missing, OrderedFactor{2}}\nFalsePositive Union{Missing, OrderedFactor{2}}\nFalsePositiveRate Union{Missing, OrderedFactor{2}}\nNegativePredictiveValue Union{Missing, OrderedFactor{2}}\nPositivePredictiveValue Union{Missing, OrderedFactor{2}}\nTrueNegative Union{Missing, OrderedFactor{2}}\nTrueNegativeRate Union{Missing, OrderedFactor{2}}\nTruePositive Union{Missing, OrderedFactor{2}}\nTruePositiveRate Union{Missing, OrderedFactor{2}}\nAccuracy Union{Missing, Finite}\nBalancedAccuracy Union{Missing, Finite}\nConfusionMatrix Union{Missing, Finite}\nKappa Union{Missing, Finite}\nMatthewsCorrelation Union{Missing, Finite}\nMisclassificationRate Union{Missing, Finite}\nMulticlassFScore Union{Missing, Finite}\nMulticlassFalseDiscoveryRate Union{Missing, Finite}\nMulticlassFalseNegative Union{Missing, Finite}\nMulticlassFalseNegativeRate Union{Missing, Finite}\nMulticlassFalsePositive Union{Missing, Finite}\nMulticlassFalsePositiveRate Union{Missing, Finite}\nMulticlassNegativePredictiveValue Union{Missing, Finite}\nMulticlassPositivePredictiveValue Union{Missing, Finite}\nMulticlassTrueNegative Union{Missing, Finite}\nMulticlassTrueNegativeRate Union{Missing, Finite}\nMulticlassTruePositive Union{Missing, Finite}\nMulticlassTruePositiveRate Union{Missing, Finite}\nMultitargetAccuracy AbstractArray{<:Union{Missing, Finite}}\nMultitargetMisclassificationRate AbstractArray{<:Union{Missing, Finite}}","category":"page"},{"location":"auto_generated_list_of_measures/#Regression-measures-(non-probabilistic)","page":"The Measures","title":"Regression measures (non-probabilistic)","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"constructor / instance aliases observation scitype\nLPLoss Union{Missing, Infinite}\nLPSumLoss Union{Missing, Infinite}\nLogCoshLoss Union{Missing, Infinite}\nMeanAbsoluteProportionalError Union{Missing, Infinite}\nRSquared Union{Missing, Infinite}\nRootMeanSquaredError Union{Missing, Infinite}\nRootMeanSquaredLogError Union{Missing, Infinite}\nRootMeanSquaredLogProportionalError Union{Missing, Infinite}\nRootMeanSquaredProportionalError Union{Missing, Infinite}\nMultitargetLPLoss AbstractArray{<:Union{Missing, Infinite}}\nMultitargetLPSumLoss AbstractArray{<:Union{Missing, Infinite}}\nMultitargetLogCoshLoss AbstractArray{<:Union{Missing, Infinite}}\nMultitargetMeanAbsoluteProportionalError AbstractArray{<:Union{Missing, Infinite}}\nMultitargetRootMeanSquaredError AbstractArray{<:Union{Missing, Infinite}}\nMultitargetRootMeanSquaredLogError AbstractArray{<:Union{Missing, Infinite}}\nMultitargetRootMeanSquaredLogProportionalError AbstractArray{<:Union{Missing, Infinite}}\nMultitargetRootMeanSquaredProportionalError AbstractArray{<:Union{Missing, Infinite}}","category":"page"},{"location":"auto_generated_list_of_measures/#Probabilistic-measures","page":"The Measures","title":"Probabilistic measures","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"These are measures where each prediction is a probability mass or density function, over the space of possible ground truth observations. Specifically, StatisticalMeasuresBase.kind_of_proxy(measure) == LearnAPI.Distribution().","category":"page"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"constructor / instance aliases observation scitype\nBrierLoss Union{Missing, Infinite, Finite}\nBrierScore Union{Missing, Infinite, Finite}\nLogLoss Union{Missing, Infinite, Finite}\nLogScore Union{Missing, Infinite, Finite}\nSphericalScore Union{Missing, Infinite, Finite}\nAreaUnderCurve Binary","category":"page"},{"location":"auto_generated_list_of_measures/#aliases","page":"The Measures","title":"List of aliases","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"Some of the measures constructed using specific parameter values have pre-defined names associated with them that are exported by StatisticalMeasures.jl These are called aliases.","category":"page"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"alias constructed with\naccuracy Accuracy\narea_under_curve AreaUnderCurve\nauc AreaUnderCurve\nbac BalancedAccuracy\nbacc BalancedAccuracy\nbalanced_accuracy BalancedAccuracy\nbrier_loss BrierLoss\nbrier_score BrierScore\nconfmat ConfusionMatrix\nconfusion_matrix ConfusionMatrix\ncross_entropy LogLoss\ncross_entropy BrierLoss\nf1score FScore\nfallout FalsePositiveRate\nfalse_discovery_rate FalseDiscoveryRate\nfalse_negative_rate FalseNegativeRate\nfalse_negative FalseNegative\nfalse_positive_rate FalsePositiveRate\nfalse_positive FalsePositive\nfalsediscovery_rate FalseDiscoveryRate\nfalsenegative_rate FalseNegativeRate\nfalsenegative FalseNegative\nfalsepositive_rate FalsePositiveRate\nfalsepositive FalsePositive\nfdr FalseDiscoveryRate\nfnr FalseNegativeRate\nfpr FalsePositiveRate\nhit_rate TruePositiveRate\nkappa Kappa\nl1_sum LPSumLoss\nl1 LPLoss\nl2_sum LPSumLoss\nl2 LPLoss\nlog_cosh_loss LogCoshLoss\nlog_cosh LogCoshLoss\nlog_loss LogLoss\nlog_score LogScore\nmacro_f1score MulticlassFScore\nmae LPLoss\nmape MeanAbsoluteProportionalError\nmatthews_correlation MatthewsCorrelation\nmav LPLoss\nmcc MatthewsCorrelation\nmcr MisclassificationRate\nmean_absolute_error LPLoss\nmean_absolute_value LPLoss\nmicro_f1score MulticlassFScore\nmisclassification_rate MisclassificationRate\nmiss_rate FalseNegativeRate\nmulticlass_f1score MulticlassFScore\nmulticlass_fallout MulticlassFalsePositiveRate\nmulticlass_false_discovery_rate MulticlassFalseDiscoveryRate\nmulticlass_false_negative_rate MulticlassFalseNegativeRate\nmulticlass_false_negative MulticlassFalseNegative\nmulticlass_false_positive_rate MulticlassFalsePositiveRate\nmulticlass_false_positive MulticlassFalsePositive\nmulticlass_falsediscovery_rate MulticlassFalseDiscoveryRate\nmulticlass_falsenegative_rate MulticlassFalseNegativeRate\nmulticlass_falsenegative MulticlassFalseNegative\nmulticlass_falsepositive_rate MulticlassFalsePositiveRate\nmulticlass_falsepositive MulticlassFalsePositive\nmulticlass_fdr MulticlassFalseDiscoveryRate\nmulticlass_fnr MulticlassFalseNegativeRate\nmulticlass_fpr MulticlassFalsePositiveRate\nmulticlass_hit_rate MulticlassTruePositiveRate\nmulticlass_miss_rate MulticlassFalseNegativeRate\nmulticlass_negative_predictive_value MulticlassNegativePredictiveValue\nmulticlass_negativepredictive_value MulticlassNegativePredictiveValue\nmulticlass_npv MulticlassNegativePredictiveValue\nmulticlass_positive_predictive_value MulticlassPositivePredictiveValue\nmulticlass_positivepredictive_value MulticlassPositivePredictiveValue\nmulticlass_ppv MulticlassPositivePredictiveValue\nmulticlass_precision MulticlassPositivePredictiveValue\nmulticlass_recall MulticlassTruePositiveRate\nmulticlass_selectivity MulticlassTrueNegativeRate\nmulticlass_sensitivity MulticlassTruePositiveRate\nmulticlass_specificity MulticlassTrueNegativeRate\nmulticlass_tnr MulticlassTrueNegativeRate\nmulticlass_tpr MulticlassTruePositiveRate\nmulticlass_true_negative_rate MulticlassTrueNegativeRate\nmulticlass_true_negative MulticlassTrueNegative\nmulticlass_true_positive_rate MulticlassTruePositiveRate\nmulticlass_true_positive MulticlassTruePositive\nmulticlass_truenegative_rate MulticlassTrueNegativeRate\nmulticlass_truenegative MulticlassTrueNegative\nmulticlass_truepositive_rate MulticlassTruePositiveRate\nmulticlass_truepositive MulticlassTruePositive\nmultitarget_accuracy MultitargetAccuracy\nmultitarget_l1_sum MultitargetLPSumLoss\nmultitarget_l1 MultitargetLPLoss\nmultitarget_l2_sum MultitargetLPSumLoss\nmultitarget_l2 MultitargetLPLoss\nmultitarget_mae MultitargetLPLoss\nmultitarget_mape MultitargetMeanAbsoluteProportionalError\nmultitarget_mape MultitargetLogCoshLoss\nmultitarget_mav MultitargetLPLoss\nmultitarget_mcr MultitargetMisclassificationRate\nmultitarget_mean_absolute_error MultitargetLPLoss\nmultitarget_mean_absolute_value MultitargetLPLoss\nmultitarget_misclassification_rate MultitargetMisclassificationRate\nmultitarget_rms MultitargetRootMeanSquaredError\nmultitarget_rmse MultitargetRootMeanSquaredError\nmultitarget_rmsl MultitargetRootMeanSquaredLogError\nmultitarget_rmsle MultitargetRootMeanSquaredLogError\nmultitarget_rmslp1 MultitargetRootMeanSquaredLogProportionalError\nmultitarget_rmsp MultitargetRootMeanSquaredProportionalError\nmultitarget_root_mean_squared_error MultitargetRootMeanSquaredError\nmultitarget_root_mean_squared_log_error MultitargetRootMeanSquaredLogError\nnegative_predictive_value NegativePredictiveValue\nnegativepredictive_value NegativePredictiveValue\nnpv NegativePredictiveValue\npositive_predictive_value PositivePredictiveValue\npositivepredictive_value PositivePredictiveValue\nppv PositivePredictiveValue\nprecision PositivePredictiveValue\nquadratic_loss BrierLoss\nquadratic_score BrierScore\nrecall TruePositiveRate\nrms RootMeanSquaredError\nrmse RootMeanSquaredError\nrmsl RootMeanSquaredLogError\nrmsle RootMeanSquaredLogError\nrmslp1 RootMeanSquaredLogProportionalError\nrmsp RootMeanSquaredProportionalError\nroot_mean_squared_error RootMeanSquaredError\nroot_mean_squared_log_error RootMeanSquaredLogError\nrsq RSquared\nrsquared RSquared\nselectivity TrueNegativeRate\nsensitivity TruePositiveRate\nspecificity TrueNegativeRate\nspherical_score SphericalScore\ntnr TrueNegativeRate\ntpr TruePositiveRate\ntrue_negative_rate TrueNegativeRate\ntrue_negative TrueNegative\ntrue_positive_rate TruePositiveRate\ntrue_positive TruePositive\ntruenegative_rate TrueNegativeRate\ntruenegative TrueNegative\ntruepositive_rate TruePositiveRate\ntruepositive TruePositive","category":"page"},{"location":"auto_generated_list_of_measures/#Reference","page":"The Measures","title":"Reference","text":"","category":"section"},{"location":"auto_generated_list_of_measures/","page":"The Measures","title":"The Measures","text":"LPLoss\nMultitargetLPLoss\nLPSumLoss\nMultitargetLPSumLoss\nRootMeanSquaredError\nMultitargetRootMeanSquaredError\nRootMeanSquaredLogError\nMultitargetRootMeanSquaredLogError\nRootMeanSquaredLogProportionalError\nMultitargetRootMeanSquaredLogProportionalError\nRootMeanSquaredProportionalError\nMultitargetRootMeanSquaredProportionalError\nMeanAbsoluteProportionalError\nMultitargetMeanAbsoluteProportionalError\nLogCoshLoss\nMultitargetLogCoshLoss\nRSquared\nConfusionMatrix\nMisclassificationRate\nMultitargetMisclassificationRate\nAccuracy\nMultitargetAccuracy\nBalancedAccuracy\nKappa\nMatthewsCorrelation\nFScore\nTruePositive\nTrueNegative\nFalsePositive\nFalseNegative\nTruePositiveRate\nTrueNegativeRate\nFalsePositiveRate\nFalseNegativeRate\nFalseDiscoveryRate\nPositivePredictiveValue\nNegativePredictiveValue\nMulticlassTruePositive\nMulticlassTrueNegative\nMulticlassFalsePositive\nMulticlassFalseNegative\nMulticlassTruePositiveRate\nMulticlassTrueNegativeRate\nMulticlassFalsePositiveRate\nMulticlassFalseNegativeRate\nMulticlassFalseDiscoveryRate\nMulticlassPositivePredictiveValue\nMulticlassNegativePredictiveValue\nMulticlassFScore\nAreaUnderCurve\nLogScore\nLogLoss\nBrierScore\nBrierLoss\nSphericalScore","category":"page"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.LPLoss","page":"The Measures","title":"StatisticalMeasures.LPLoss","text":"LPLoss(; p=2)\n\nReturn a callable measure for computing the L^p loss. Aliases: l1, l2, mae, mav, mean_absolute_error, mean_absolute_value.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the LPLoss constructor (e.g., m = LPLoss()) on predictions ŷ, given ground truth observations y. Specifically, return the mean of y_i - y_i^p over all pairs of observations (y_i y_i) in (ŷ, y), or more generally, the mean of weighted versions of those values. For the weighted sum use LPSumLoss instead.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = ``L^p`` loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetLPLoss","page":"The Measures","title":"StatisticalMeasures.MultitargetLPLoss","text":"MultitargetLPLoss(; p=2, atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget L^p loss. Aliases: multitarget_l1, multitarget_l2, multitarget_mae, multitarget_mav, multitarget_mean_absolute_error, multitarget_mean_absolute_value.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetLPLoss constructor (e.g., m = MultitargetLPLoss()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of LPLoss. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:AbstractArray{<:Union{Missing,Infinite}}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multitarget ``L^p`` loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.LPSumLoss","page":"The Measures","title":"StatisticalMeasures.LPSumLoss","text":"LPSumLoss(; p=2)\n\nReturn a callable measure for computing the L^p sum loss. Aliases: l1_sum, l2_sum.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the LPSumLoss constructor (e.g., m = LPSumLoss()) on predictions ŷ, given ground truth observations y. Specifically, compute the (weighted) sum of y_i - yᵢ^p over all pairs of observations (y_i yᵢ) in (ŷ, y). For the weighted mean use LPLoss instead.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = ``L^p`` sum loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetLPSumLoss","page":"The Measures","title":"StatisticalMeasures.MultitargetLPSumLoss","text":"MultitargetLPSumLoss(; p=2, atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget L^p sum loss. Aliases: multitarget_l1_sum, multitarget_l2_sum.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetLPSumLoss constructor (e.g., m = MultitargetLPSumLoss()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of LPSumLoss. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:AbstractArray{<:Union{Missing,Infinite}}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = multitarget ``L^p`` sum loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.RootMeanSquaredError","page":"The Measures","title":"StatisticalMeasures.RootMeanSquaredError","text":"RootMeanSquaredError()\n\nReturn a callable measure for computing the root mean squared error. Aliases: rms, rmse, root_mean_squared_error.\n\nRootMeanSquaredError()(ŷ, y)\nRootMeanSquaredError()(ŷ, y, weights)\nRootMeanSquaredError()(ŷ, y, class_weights::AbstractDict)\nRootMeanSquaredError()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate RootMeanSquaredError() on predictions ŷ, given ground truth observations y.  Specifically, compute the mean of y_i-y_i^2 over all pairs of observations (y_i y_i) in (ŷ, y), and return the square root of the result. More generally, pre-multiply the squared deviations by the specified weights.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(RootMeanSquaredError(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = root mean squared error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetRootMeanSquaredError","page":"The Measures","title":"StatisticalMeasures.MultitargetRootMeanSquaredError","text":"MultitargetRootMeanSquaredError(; atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget root mean squared error. Aliases: multitarget_rms, multitarget_rmse, multitarget_root_mean_squared_error.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetRootMeanSquaredError constructor (e.g., m = MultitargetRootMeanSquaredError()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of RootMeanSquaredError. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:AbstractArray{<:Union{Missing,Infinite}}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = multitarget root mean squared error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.RootMeanSquaredLogError","page":"The Measures","title":"StatisticalMeasures.RootMeanSquaredLogError","text":"RootMeanSquaredLogError()\n\nReturn a callable measure for computing the root mean squared log error. Aliases: rmsl, rmsle, root_mean_squared_log_error.\n\nRootMeanSquaredLogError()(ŷ, y)\nRootMeanSquaredLogError()(ŷ, y, weights)\nRootMeanSquaredLogError()(ŷ, y, class_weights::AbstractDict)\nRootMeanSquaredLogError()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate RootMeanSquaredLogError() on predictions ŷ, given ground truth observations y. Specifically, return the mean of (log(y)_i - log(y_i))^2 over all pairs of observations (y_i y_i) in (ŷ, y), and return the square root of the result. More generally, pre-multiply the values averaged by the specified weights. To include an offset, use RootMeanSquaredLogProportionalError instead.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(RootMeanSquaredLogError(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = root mean squared log error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetRootMeanSquaredLogError","page":"The Measures","title":"StatisticalMeasures.MultitargetRootMeanSquaredLogError","text":"MultitargetRootMeanSquaredLogError(; atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget root mean squared log error. Aliases: multitarget_rmsl, multitarget_rmsle, multitarget_root_mean_squared_log_error.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetRootMeanSquaredLogError constructor (e.g., m = MultitargetRootMeanSquaredLogError()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of RootMeanSquaredLogError. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:AbstractArray{<:Union{Missing,Infinite}}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = multitarget root mean squared log error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.RootMeanSquaredLogProportionalError","page":"The Measures","title":"StatisticalMeasures.RootMeanSquaredLogProportionalError","text":"RootMeanSquaredLogProportionalError(; offset=1)\n\nReturn a callable measure for computing the root mean squared log proportional error. Aliases: rmslp1.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the RootMeanSquaredLogProportionalError constructor (e.g., m = RootMeanSquaredLogProportionalError()) on predictions ŷ, given ground truth observations y. Specifically, compute the mean of (log(y_i + δ) - log(y_i + δ))^2 over all pairs of observations (y_i y_i) in (ŷ, y), and return the square root. More generally, pre-multiply the values averaged by the specified weights. Here δ=offset, which is 1 by default. This is the same as RootMeanSquaredLogError but adds an offset.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = root mean squared log proportional error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetRootMeanSquaredLogProportionalError","page":"The Measures","title":"StatisticalMeasures.MultitargetRootMeanSquaredLogProportionalError","text":"MultitargetRootMeanSquaredLogProportionalError(; offset=1, atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget root mean squared log proportional error. Aliases: multitarget_rmslp1.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetRootMeanSquaredLogProportionalError constructor (e.g., m = MultitargetRootMeanSquaredLogProportionalError()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of RootMeanSquaredLogProportionalError. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = multitarget root mean squared log proportional error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.RootMeanSquaredProportionalError","page":"The Measures","title":"StatisticalMeasures.RootMeanSquaredProportionalError","text":"RootMeanSquaredProportionalError(; tol=eps())\n\nReturn a callable measure for computing the root mean squared proportional error. Aliases: rmsp.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the RootMeanSquaredProportionalError constructor (e.g., m = RootMeanSquaredProportionalError()) on predictions ŷ, given ground truth observations y. Specifically, compute the mean of (y_i-y_i over y_i)^2 over all pairs of observations (y_i y_i) in (ŷ, y), and return the square root of the result. More generally, pre-multiply the values averaged by the specified weights. Terms for which y_i<tol are dropped in the summation, but counts still contribute to the mean normalization factor.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = root mean squared proportional error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetRootMeanSquaredProportionalError","page":"The Measures","title":"StatisticalMeasures.MultitargetRootMeanSquaredProportionalError","text":"MultitargetRootMeanSquaredProportionalError(; tol=eps(), atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget root mean squared proportional error. Aliases: multitarget_rmsp.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetRootMeanSquaredProportionalError constructor (e.g., m = MultitargetRootMeanSquaredProportionalError()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of RootMeanSquaredProportionalError. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.RootMean{Int64}(2)\nhuman_name = multitarget root mean squared proportional error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MeanAbsoluteProportionalError","page":"The Measures","title":"StatisticalMeasures.MeanAbsoluteProportionalError","text":"MeanAbsoluteProportionalError(; tol=eps())\n\nReturn a callable measure for computing the mean absolute proportional error. Aliases: mape.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MeanAbsoluteProportionalError constructor (e.g., m = MeanAbsoluteProportionalError()) on predictions ŷ, given ground truth observations y. Specifically, return the mean of y_i-y_i over y_i over all pairs of observations (y_i y_i) in (ŷ, y). More generally, pre-multiply the values averaged by the specified weights. Terms for which y_i<tol are dropped in the summation, but corresponding weights (or counts) still contribute to the mean normalization factor.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = mean absolute proportional error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetMeanAbsoluteProportionalError","page":"The Measures","title":"StatisticalMeasures.MultitargetMeanAbsoluteProportionalError","text":"MultitargetMeanAbsoluteProportionalError(; tol=eps(), atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget mean absolute proportional error. Aliases: multitarget_mape.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetMeanAbsoluteProportionalError constructor (e.g., m = MultitargetMeanAbsoluteProportionalError()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of MeanAbsoluteProportionalError. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multitarget mean absolute proportional error\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.LogCoshLoss","page":"The Measures","title":"StatisticalMeasures.LogCoshLoss","text":"LogCoshLoss()\n\nReturn a callable measure for computing the log cosh loss. Aliases: log_cosh, log_cosh_loss.\n\nLogCoshLoss()(ŷ, y)\nLogCoshLoss()(ŷ, y, weights)\nLogCoshLoss()(ŷ, y, class_weights::AbstractDict)\nLogCoshLoss()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate LogCoshLoss() on predictions ŷ, given ground truth observations y. Return the mean of log(cosh(y_i-y_i)) over all pairs of observations (y_i y_i) in (ŷ, y). More generally, pre-multiply the values averaged by the specified weights.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(LogCoshLoss(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = log cosh loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetLogCoshLoss","page":"The Measures","title":"StatisticalMeasures.MultitargetLogCoshLoss","text":"MultitargetLogCoshLoss(; atomic_weights=nothing)\n\nReturn a callable measure for computing the multitarget log cosh loss. Aliases: multitarget_mape.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MultitargetLogCoshLoss constructor (e.g., m = MultitargetLogCoshLoss()) on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of LogCoshLoss. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Infinite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multitarget log cosh loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.RSquared","page":"The Measures","title":"StatisticalMeasures.RSquared","text":"RSquared()\n\nReturn a callable measure for computing the R² coefficient. Aliases: rsq, rsquared.\n\nRSquared()(ŷ, y)\n\nEvaluate RSquared() on predictions ŷ, given ground truth observations y. Specifically, return the value of\n\n1 - fracᵢ (y_i- y_i)^2ᵢ y - y_i)^2\n\nwhere y denote the mean of the y_i. Also known as R-squared or the coefficient of determination, the R² coefficients is suitable for interpreting linear regression analysis (Chicco et al., 2021).\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Infinite,Missing}. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = R² coefficient\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.ConfusionMatrix","page":"The Measures","title":"StatisticalMeasures.ConfusionMatrix","text":"ConfusionMatrix(; levels=nothing, rev=false, perm=nothing, checks=true)\n\nReturn a callable measure for computing the confusion matrix. Aliases: confmat, confusion_matrix.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the ConfusionMatrix constructor (e.g., m = ConfusionMatrix()) on predictions ŷ, given ground truth observations y. See the Confusion matrix wikipedia article.\n\nElements of a confusion matrix can always be accessed by level - see the example below. To flag the confusion matrix as ordered, and hence index-accessible, do one of the following:\n\nSupply ordered CategoricalArray inputs ŷ and y\nExplicitly specify levels or one of rev, perm\n\nNote that == for two confusion matrices is stricter when both are ordered.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). \n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nFor more on the type of object returned and its interface, see ConfusionMatrices.ConfusionMatrix.\n\nExample\n\n\nusing StatisticalMeasures\n\ny = [\"a\", \"b\", \"a\", \"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\nŷ = [\"b\", \"a\", \"a\", \"b\", \"a\", \"b\", \"b\", \"b\", \"a\", \"a\"]\n\njulia> cm = ConfusionMatrix()(ŷ, y)  # or `confmat((ŷ, y)`.\n\n              ┌───────────────────────────┐\n              │       Ground Truth        │\n┌─────────────┼─────────────┬─────────────┤\n│  Predicted  │      a      │      b      │\n├─────────────┼─────────────┼─────────────┤\n│      a      │      2      │      3      │\n├─────────────┼─────────────┼─────────────┤\n│      b      │      4      │      1      │\n└─────────────┴─────────────┴─────────────┘\n\njulia> cm(\"a\", \"b\")\n3\n\nCore algorithm:  ConfusionMatrices.confmat.\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Unoriented()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = confusion matrix\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MisclassificationRate","page":"The Measures","title":"StatisticalMeasures.MisclassificationRate","text":"MisclassificationRate()\n\nReturn a callable measure for computing the misclassification rate. Aliases: misclassification_rate, mcr.\n\nMisclassificationRate()(ŷ, y)\nMisclassificationRate()(ŷ, y, weights)\nMisclassificationRate()(ŷ, y, class_weights::AbstractDict)\nMisclassificationRate()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate MisclassificationRate() on predictions ŷ, given ground truth observations y. That, is, return the proportion of predictions ŷᵢ that are different from the corresponding ground truth yᵢ. More generally, average the specified weights over incorrectly identified observations. Can also be called on a confusion matrix. See ConfusionMatrix.\n\nThis metric is invariant to class reordering.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(MisclassificationRate(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). \n\nSee also StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = misclassification rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetMisclassificationRate","page":"The Measures","title":"StatisticalMeasures.MultitargetMisclassificationRate","text":"MultitargetMisclassificationRate()\n\nReturn a callable measure for computing the multitarget misclassification rate. Aliases: multitarget_misclassification_rate, multitarget_mcr.\n\nMultitargetMisclassificationRate()(ŷ, y)\nMultitargetMisclassificationRate()(ŷ, y, weights)\nMultitargetMisclassificationRate()(ŷ, y, class_weights::AbstractDict)\nMultitargetMisclassificationRate()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate MultitargetMisclassificationRate() on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of MisclassificationRate. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(MultitargetMisclassificationRate(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Finite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multitarget misclassification rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.Accuracy","page":"The Measures","title":"StatisticalMeasures.Accuracy","text":"Accuracy()\n\nReturn a callable measure for computing the accuracy. Aliases: accuracy.\n\nAccuracy()(ŷ, y)\nAccuracy()(ŷ, y, weights)\nAccuracy()(ŷ, y, class_weights::AbstractDict)\nAccuracy()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate Accuracy() on predictions ŷ, given ground truth observations y. That is, compute the proportion of predictions ŷᵢ that agree with the corresponding ground truth yᵢ. More generally, average the specified weights over all correctly predicted observations.  Can also be called on a confusion matrix. See ConfusionMatrix.\n\nThis metric is invariant to class reordering.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(Accuracy(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). \n\nSee also ConfusionMatrices.ConfusionMatrix and ConfusionMatrix. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = accuracy\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MultitargetAccuracy","page":"The Measures","title":"StatisticalMeasures.MultitargetAccuracy","text":"MultitargetAccuracy()\n\nReturn a callable measure for computing the multitarget accuracy. Aliases: multitarget_accuracy.\n\nMultitargetAccuracy()(ŷ, y)\nMultitargetAccuracy()(ŷ, y, weights)\nMultitargetAccuracy()(ŷ, y, class_weights::AbstractDict)\nMultitargetAccuracy()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate MultitargetAccuracy() on predictions ŷ, given ground truth observations y. Specifically, compute the multi-target version of Accuracy. Some kinds of tabular input are supported.\n\nIn array arguments the last dimension is understood to be the observation dimension. The atomic_weights are weights for each component of the multi-target. Unless equal to nothing (uniform weights) the length of atomic_weights will generally match the number of columns of y, if y is a table, or the number of rows of y, if y is a matrix. \n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(MultitargetAccuracy(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). Alternatively, y and ŷ can be some types of table, provided elements have the approprate scitype. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = AbstractArray{<:Union{Missing, ScientificTypesBase.Finite}}\ncan_consume_tables = true\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multitarget accuracy\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.BalancedAccuracy","page":"The Measures","title":"StatisticalMeasures.BalancedAccuracy","text":"BalancedAccuracy(; adjusted=false)\n\nReturn a callable measure for computing the balanced accuracy. Aliases: balanced_accuracy, bacc, bac.\n\nm(ŷ, y)\nm(ŷ, y, weights)\n\nEvaluate some measure m returned by the BalancedAccuracy constructor (e.g., m = BalancedAccuracy()) on predictions ŷ, given ground truth observations y. This is a variation of Accuracy compensating for class imbalance. See https://en.wikipedia.org/wiki/Precisionandrecall#Imbalanced_data.\n\nSetting adjusted=true rescales the score in the way prescribed in L. Mosley (2013): A balanced approach to the multi-class imbalance problem. PhD thesis, Iowa State University. In the binary case, the adjusted balanced accuracy is also known as Youden’s J statistic, or informedness.\n\nThis metric is invariant to class reordering.\n\nAny iterator with a length generating Real elements can be used for weights. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = balanced accuracy\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.Kappa","page":"The Measures","title":"StatisticalMeasures.Kappa","text":"Kappa()\n\nReturn a callable measure for computing the Cohen's κ. Aliases: kappa.\n\nKappa()(ŷ, y)\nKappa()(ŷ, y, weights)\n\nEvaluate Kappa() on predictions ŷ, given ground truth observations y. For details, see the Cohen's κ Wikipedia article. Can also be called on confusion matrices. See ConfusionMatrix.\n\nThis metric is invariant to class reordering.\n\nAny iterator with a length generating Real elements can be used for weights. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). \n\nSee also StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix. \n\nCore algorithm: Functions.kappa\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = Cohen's κ\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MatthewsCorrelation","page":"The Measures","title":"StatisticalMeasures.MatthewsCorrelation","text":"MatthewsCorrelation()\n\nReturn a callable measure for computing the Matthew's correlation. Aliases: matthews_correlation, mcc.\n\nMatthewsCorrelation()(ŷ, y)\n\nEvaluate MatthewsCorrelation() on predictions ŷ, given ground truth observations y. See the Wikipedia Matthew's Correlation page. Can also be called on confusion matrices.  See ConfusionMatrix.\n\nThis metric is invariant to class reordering.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Finite,Missing} (multiclass classification). \n\nSee also StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.matthews_correlation\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = Matthew's correlation\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.FScore","page":"The Measures","title":"StatisticalMeasures.FScore","text":"FScore(; beta=1.0, levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the F_β score. Aliases: f1score.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the FScore constructor (e.g., m = FScore()) on predictions ŷ, given ground truth observations y. This is the one-parameter generalization, F_β, of the F-measure or balanced F-score. Choose beta=β in the range 0, using beta > 1 to emphasize recall (TruePositiveRate) over precision (PositivePredictiveValue). When beta = 1, the score is the harmonic mean of precision and recall. See the F1 score Wikipedia page for details.\n\nIf ordering classes (levels) on the basis of the eltype of y, then the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nFScore mesaures can also be called on a confusion matrix.  See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.fscore \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = ``F_β`` score\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.TruePositive","page":"The Measures","title":"StatisticalMeasures.TruePositive","text":"TruePositive(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the true positive count. Aliases: true_positive, truepositive.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the TruePositive constructor (e.g., m = TruePositive()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassTruePositive, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.true_positive\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = true positive count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.TrueNegative","page":"The Measures","title":"StatisticalMeasures.TrueNegative","text":"TrueNegative(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the true negative count. Aliases: true_negative, truenegative.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the TrueNegative constructor (e.g., m = TrueNegative()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassTrueNegative, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.true_negative\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = true negative count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.FalsePositive","page":"The Measures","title":"StatisticalMeasures.FalsePositive","text":"FalsePositive(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the false positive count. Aliases: false_positive, falsepositive.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the FalsePositive constructor (e.g., m = FalsePositive()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassFalsePositive, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.false_positive\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = false positive count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.FalseNegative","page":"The Measures","title":"StatisticalMeasures.FalseNegative","text":"FalseNegative(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the false negative count. Aliases: false_negative, falsenegative.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the FalseNegative constructor (e.g., m = FalseNegative()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassFalseNegative, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.false_negative\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = false negative count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.TruePositiveRate","page":"The Measures","title":"StatisticalMeasures.TruePositiveRate","text":"TruePositiveRate(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the true positive rate. Aliases: true_positive_rate, truepositive_rate, tpr, sensitivity, recall, hit_rate.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the TruePositiveRate constructor (e.g., m = TruePositiveRate()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassTruePositiveRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.true_positive_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = true positive rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.TrueNegativeRate","page":"The Measures","title":"StatisticalMeasures.TrueNegativeRate","text":"TrueNegativeRate(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the true negative rate. Aliases: true_negative_rate, truenegative_rate, tnr, specificity, selectivity.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the TrueNegativeRate constructor (e.g., m = TrueNegativeRate()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassTrueNegativeRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.true_negative_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = true negative rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.FalsePositiveRate","page":"The Measures","title":"StatisticalMeasures.FalsePositiveRate","text":"FalsePositiveRate(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the false positive rate. Aliases: false_positive_rate, falsepositive_rate, fpr, fallout.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the FalsePositiveRate constructor (e.g., m = FalsePositiveRate()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassFalsePositiveRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.false_positive_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = false positive rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.FalseNegativeRate","page":"The Measures","title":"StatisticalMeasures.FalseNegativeRate","text":"FalseNegativeRate(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the false negative rate. Aliases: false_negative_rate, falsenegative_rate, fnr, miss_rate.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the FalseNegativeRate constructor (e.g., m = FalseNegativeRate()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassFalseNegativeRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.false_negative_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = false negative rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.FalseDiscoveryRate","page":"The Measures","title":"StatisticalMeasures.FalseDiscoveryRate","text":"FalseDiscoveryRate(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the false discovery rate. Aliases: false_discovery_rate, falsediscovery_rate, fdr.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the FalseDiscoveryRate constructor (e.g., m = FalseDiscoveryRate()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassFalseDiscoveryRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.false_discovery_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = false discovery rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.PositivePredictiveValue","page":"The Measures","title":"StatisticalMeasures.PositivePredictiveValue","text":"PositivePredictiveValue(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the positive predictive value. Aliases: positive_predictive_value, ppv, positivepredictive_value, precision.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the PositivePredictiveValue constructor (e.g., m = PositivePredictiveValue()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassPositivePredictiveValue, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.positive_predictive_value\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = positive predictive value\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.NegativePredictiveValue","page":"The Measures","title":"StatisticalMeasures.NegativePredictiveValue","text":"NegativePredictiveValue(; levels=nothing, rev=nothing, checks=true)\n\nReturn a callable measure for computing the negative predictive value. Aliases: negative_predictive_value, negativepredictive_value, npv.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the NegativePredictiveValue constructor (e.g., m = NegativePredictiveValue()) on predictions ŷ, given ground truth observations y. When ordering classes (levels) on the basis of the eltype of y, the second level is the \"positive\" class. To reverse roles, specify rev=true.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix. See ConfusionMatrix.\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nSee also MulticlassNegativePredictiveValue, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.negative_predictive_value\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.OrderedFactor{2}}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = negative predictive value\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassTruePositive","page":"The Measures","title":"StatisticalMeasures.MulticlassTruePositive","text":"MulticlassTruePositive(; levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class true positive count. Aliases: multiclass_true_positive, multiclass_truepositive.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the MulticlassTruePositive constructor (e.g., m = MulticlassTruePositive()) on predictions ŷ, given ground truth observations y. \n\nThis is a one-versus-rest version of the binary measure TruePositive, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix.  Construct confusion matrices using ConfusionMatrix.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also TruePositive, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_true_positive\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = multi-class true positive count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassTrueNegative","page":"The Measures","title":"StatisticalMeasures.MulticlassTrueNegative","text":"MulticlassTrueNegative(; levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class true negative count. Aliases: multiclass_true_negative, multiclass_truenegative.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the MulticlassTrueNegative constructor (e.g., m = MulticlassTrueNegative()) on predictions ŷ, given ground truth observations y. \n\nThis is a one-versus-rest version of the binary measure TrueNegative, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix.  Construct confusion matrices using ConfusionMatrix.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also TrueNegative, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_true_negative\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = multi-class true negative count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassFalsePositive","page":"The Measures","title":"StatisticalMeasures.MulticlassFalsePositive","text":"MulticlassFalsePositive(; levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class false positive count. Aliases: multiclass_false_positive, multiclass_falsepositive.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the MulticlassFalsePositive constructor (e.g., m = MulticlassFalsePositive()) on predictions ŷ, given ground truth observations y. \n\nThis is a one-versus-rest version of the binary measure FalsePositive, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix.  Construct confusion matrices using ConfusionMatrix.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also FalsePositive, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_false_positive\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = multi-class false positive count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassFalseNegative","page":"The Measures","title":"StatisticalMeasures.MulticlassFalseNegative","text":"MulticlassFalseNegative(; levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class false negative count. Aliases: multiclass_false_negative, multiclass_falsenegative.\n\nm(ŷ, y)\n\nEvaluate some measure m returned by the MulticlassFalseNegative constructor (e.g., m = MulticlassFalseNegative()) on predictions ŷ, given ground truth observations y. \n\nThis is a one-versus-rest version of the binary measure FalseNegative, returning a dictionary keyed on target class (level), or a vector (see options below), instead of a single number, even on binary data.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nm can also be called on a confusion matrix.  Construct confusion matrices using ConfusionMatrix.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also FalseNegative, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_false_negative\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Sum()\nhuman_name = multi-class false negative count\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassTruePositiveRate","page":"The Measures","title":"StatisticalMeasures.MulticlassTruePositiveRate","text":"MulticlassTruePositiveRate(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class true positive rate. Aliases: multiclass_true_positive_rate, multiclass_truepositive_rate, multiclass_tpr, multiclass_sensitivity, multiclass_recall, multiclass_hit_rate.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassTruePositiveRate constructor (e.g., m = MulticlassTruePositiveRate()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary TruePositiveRate. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also TruePositiveRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_true_positive_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class true positive rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassTrueNegativeRate","page":"The Measures","title":"StatisticalMeasures.MulticlassTrueNegativeRate","text":"MulticlassTrueNegativeRate(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class true negative rate. Aliases: multiclass_true_negative_rate, multiclass_truenegative_rate, multiclass_tnr, multiclass_specificity, multiclass_selectivity.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassTrueNegativeRate constructor (e.g., m = MulticlassTrueNegativeRate()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary TrueNegativeRate. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also TrueNegativeRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_true_negative_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class true negative rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassFalsePositiveRate","page":"The Measures","title":"StatisticalMeasures.MulticlassFalsePositiveRate","text":"MulticlassFalsePositiveRate(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class false positive rate. Aliases: multiclass_false_positive_rate, multiclass_falsepositive_rate, multiclass_fpr, multiclass_fallout.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassFalsePositiveRate constructor (e.g., m = MulticlassFalsePositiveRate()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary FalsePositiveRate. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also FalsePositiveRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_false_positive_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class false positive rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassFalseNegativeRate","page":"The Measures","title":"StatisticalMeasures.MulticlassFalseNegativeRate","text":"MulticlassFalseNegativeRate(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class false negative rate. Aliases: multiclass_false_negative_rate, multiclass_falsenegative_rate, multiclass_fnr, multiclass_miss_rate.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassFalseNegativeRate constructor (e.g., m = MulticlassFalseNegativeRate()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary FalseNegativeRate. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also FalseNegativeRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_false_negative_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class false negative rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassFalseDiscoveryRate","page":"The Measures","title":"StatisticalMeasures.MulticlassFalseDiscoveryRate","text":"MulticlassFalseDiscoveryRate(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class false discovery rate. Aliases: multiclass_false_discovery_rate, multiclass_falsediscovery_rate, multiclass_fdr.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassFalseDiscoveryRate constructor (e.g., m = MulticlassFalseDiscoveryRate()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary FalseDiscoveryRate. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also FalseDiscoveryRate, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_false_discovery_rate\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class false discovery rate\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassPositivePredictiveValue","page":"The Measures","title":"StatisticalMeasures.MulticlassPositivePredictiveValue","text":"MulticlassPositivePredictiveValue(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class positive predictive value. Aliases: multiclass_positive_predictive_value, multiclass_ppv, multiclass_positivepredictive_value, multiclass_precision.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassPositivePredictiveValue constructor (e.g., m = MulticlassPositivePredictiveValue()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary PositivePredictiveValue. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also PositivePredictiveValue, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_positive_predictive_value\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class positive predictive value\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassNegativePredictiveValue","page":"The Measures","title":"StatisticalMeasures.MulticlassNegativePredictiveValue","text":"MulticlassNegativePredictiveValue(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class negative predictive value. Aliases: multiclass_negative_predictive_value, multiclass_negativepredictive_value, multiclass_npv.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassNegativePredictiveValue constructor (e.g., m = MulticlassNegativePredictiveValue()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary NegativePredictiveValue. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also NegativePredictiveValue, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_negative_predictive_value\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class negative predictive value\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.MulticlassFScore","page":"The Measures","title":"StatisticalMeasures.MulticlassFScore","text":"MulticlassFScore(; average=macro_avg, levels=nothing, more_options...)\n\nReturn a callable measure for computing the multi-class F_β score. Aliases: macro_f1score, micro_f1score, multiclass_f1score.\n\nm(ŷ, y)\nm(ŷ, y, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the MulticlassFScore constructor (e.g., m = MulticlassFScore()) on predictions ŷ, given ground truth observations y. \n\nThis is an averaged one-versus-rest version of the binary FScore. Or it can return a dictionary keyed on target class (or a vector); see average options below.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nYou can also call m on confusion matrices. Construct confusion matrices using ConfusionMatrix.\n\nThe keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{OrderedFactor{2},Missing} (binary classification where definition of \"positive\" class matters). \n\nKeyword options\n\nbeta=1.0: parameter in the range 0, emphasizing recall over precision for beta > 1, except in the case average=MicroAvg(), when it has no effect.\n\naverage=MacroAvg(): one of: NoAvg(), MacroAvg(), MicroAvg() (names owned and exported by StatisticalMeasuresBase.jl.) See J. Opitz and S. Burst (2019). \"Macro F1 and Macro F1\", arXiv.\n\nreturn_type=LittleDict: type of returned measurement for average=NoAvg() case; if LittleDict, then keyed on levels of the target; can also be Vector\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nSee also FScore, StatisticalMeasures.ConfusionMatrices.ConfusionMatrix and ConfusionMatrix.\n\nCore algorithm: Functions.multiclass_fscore\n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.LiteralTarget()\nobservation_scitype = Union{Missing, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = multi-class ``F_β`` score\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.AreaUnderCurve","page":"The Measures","title":"StatisticalMeasures.AreaUnderCurve","text":"AreaUnderCurve()\n\nReturn a callable measure for computing the area under the receiver operator characteritic. Aliases: auc, area_under_curve.\n\nAreaUnderCurve()(ŷ, y)\n\nEvaluate AreaUnderCurve() on predictions ŷ, given ground truth observations y. See the Recevier operator chararacteristic (ROC) Wikipedia article for a definition. It is expected that ŷ be a vector of distributions over the binary set of unique elements of y; specifically, ŷ should have eltype <:UnivariateFinite from the CategoricalDistributions.jl package.\n\nImplementation is based on the Mann-Whitney U statistic.  See the Whitney U test Wikipedia page for details. \n\nCore implementation: Functions.auc.\n\nThis metric is invariant to class reordering.\n\nGenerally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:ScientificTypesBase.Binary. \n\nSee also roc_curve. \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.Distribution()\nobservation_scitype = ScientificTypesBase.Binary\ncan_consume_tables = false\nsupports_weights = false\nsupports_class_weights = false\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = area under the receiver operator characteritic\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.LogScore","page":"The Measures","title":"StatisticalMeasures.LogScore","text":"LogScore(; tol=eps())\n\nReturn a callable measure for computing the log score. Aliases: log_score.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the LogScore constructor (e.g., m = LogScore()) on predictions ŷ, given ground truth observations y. The score is a mean of observational scores. More generally, observational scores are pre-multiplied by the specified weights before avaraging. See below for the form that probabilistic predictions ŷ should take. Raw probabilities are clamped away from 0 and 1. Specifically, if p is the probability mass/density function evaluated at given observed ground truth observation η, then the score for that example is defined as\n\nlog(clamp(p(η), tol, 1 - tol).\n\nFor example, for a binary target with \"yes\"/\"no\" labels, if the probabilistic prediction scores 0.8 for a \"yes\", then for a corresponding ground truth observation of \"no\", that example's contribution to the score is log(0.2).\n\nThe predictions ŷ should be a vector of UnivariateFinite distributions from CategoricalDistritutions.jl, in the case of Finite target y (a CategoricalVector) and should otherwise be a supported Distributions.UnivariateDistribution such as Normal or Poisson.\n\nSee also LogLoss, which differs only in sign.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(m, ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Missing,T} where T is Continuous or Count (for respectively continuous or discrete Distribution.jl objects in ŷ) or  OrderedFactor or Multiclass (for UnivariateFinite distributions in ŷ). \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.Distribution()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = log score\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.LogLoss","page":"The Measures","title":"StatisticalMeasures.LogLoss","text":"LogLoss(; tol=eps())\n\nReturn a callable measure for computing the log loss. Aliases: log_loss, cross_entropy.\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate some measure m returned by the LogLoss constructor (e.g., m = LogLoss()) on predictions ŷ, given ground truth observations y. For details, see LogScore, which differs only by a sign.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Missing,T} where T is Continuous or Count (for respectively continuous or discrete Distribution.jl objects in ŷ) or  OrderedFactor or Multiclass (for UnivariateFinite distributions in ŷ). \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.Distribution()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = log loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.BrierScore","page":"The Measures","title":"StatisticalMeasures.BrierScore","text":"BrierScore()\n\nReturn a callable measure for computing the brier score. Aliases: brier_score, quadratic_score.\n\nBrierScore()(ŷ, y)\nBrierScore()(ŷ, y, weights)\nBrierScore()(ŷ, y, class_weights::AbstractDict)\nBrierScore()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate BrierScore() on predictions ŷ, given ground truth observations y. The score is a mean of observational scores. More generally, observational scores are pre-multiplied by the specified weights before avaraging. See below for the form that probabilistic predictions ŷ should take.\n\nConvention as in Gneiting and Raftery (2007), \"StrictlyProper Scoring Rules, Prediction, and Estimation\"\n\nFinite case. If p(η) is the predicted probability for a single observation η, and C all possible classes, then the corresponding score for that example is given by\n\n2p(η) - left(sum_c  C p(c)^2right) - 1\n\nWarning. BrierScore() is a \"score\" in the sense that bigger is better (with 0 optimal, and all other values negative). In Brier's original 1950 paper, and many other places, it has the opposite sign, despite the name. Moreover, the present implementation does not treat the binary case as special, so that the score may differ in the binary case by a factor of two from usage elsewhere.\n\nInfinite case. Replacing the sum above with an integral does not lead to the formula adopted here in the case of Continuous or Count target y. Rather the convention in the paper cited above is adopted, which means returning a score of\n\n2p(η) -  p(t)^2 dt\n\nin the Continuous case (p the probablity density function) or\n\n2p(η) - _t p(t)^2\n\nin the Count case (p the probablity mass function).\n\nThe predictions ŷ should be a vector of UnivariateFinite distributions from CategoricalDistritutions.jl, in the case of Finite target y (a CategoricalVector) and should otherwise be a supported Distributions.UnivariateDistribution such as Normal or Poisson.\n\nSee also BrierLoss, which differs only in sign.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(BrierScore(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Missing,T} where T is Continuous or Count (for respectively continuous or discrete Distribution.jl objects in ŷ) or  OrderedFactor or Multiclass (for UnivariateFinite distributions in ŷ). \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.Distribution()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = brier score\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.BrierLoss","page":"The Measures","title":"StatisticalMeasures.BrierLoss","text":"BrierLoss()\n\nReturn a callable measure for computing the brier loss. Aliases: brier_loss, cross_entropy, quadratic_loss.\n\nBrierLoss()(ŷ, y)\nBrierLoss()(ŷ, y, weights)\nBrierLoss()(ŷ, y, class_weights::AbstractDict)\nBrierLoss()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate BrierLoss() on predictions ŷ, given ground truth observations y. For details, see BrierScore, which differs only by a sign.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Missing,T} where T is Continuous or Count (for respectively continuous or discrete Distribution.jl objects in ŷ) or  OrderedFactor or Multiclass (for UnivariateFinite distributions in ŷ). \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = false\nkind_of_proxy = LearnAPI.Distribution()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Loss()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = brier loss\n\n\n\n\n\n","category":"function"},{"location":"auto_generated_list_of_measures/#StatisticalMeasures.SphericalScore","page":"The Measures","title":"StatisticalMeasures.SphericalScore","text":"SphericalScore()\n\nReturn a callable measure for computing the spherical score. Aliases: spherical_score.\n\nSphericalScore()(ŷ, y)\nSphericalScore()(ŷ, y, weights)\nSphericalScore()(ŷ, y, class_weights::AbstractDict)\nSphericalScore()(ŷ, y, weights, class_weights::AbstractDict)\n\nEvaluate SphericalScore() on predictions ŷ, given ground truth observations y. The score is a mean of observational scores. More generally, observational scores are pre-multiplied by the specified weights before avaraging. See below for the form that probabilistic predictions ŷ should take.\n\nConvention as in Gneiting and Raftery (2007), \"StrictlyProper Scoring Rules, Prediction, and Estimation\": If y takes on a finite number of classes C and p(y) is the predicted probability for a single observation y, then the corresponding score for that example is given by\n\np(y)^α  left(sum_η  C p(η)^αright)^1-α - 1\n\nwhere α is the measure parameter alpha.\n\nIn the case the predictions ŷ are continuous probability distributions, such as Distributions.Normal, replace the above sum with an integral, and interpret p as the probablity density function. In case of discrete distributions over the integers, such as Distributions.Poisson, sum over all integers instead of C.\n\nAny iterator with a length generating Real elements can be used for weights. The keys of class_weights should include all conceivable values for observations in y, and values should be Real. \n\nMeasurements are aggregated. To obtain a separate measurement for each observation, use the syntax measurements(SphericalScore(), ŷ, y). Generally, an observation obs in MLUtils.eachobs(y) is expected to satisfy ScientificTypes.scitype(obs)<:Union{Missing,T} where T is Continuous or Count (for respectively continuous or discrete Distribution.jl objects in ŷ) or  OrderedFactor or Multiclass (for UnivariateFinite distributions in ŷ). \n\nFor a complete dictionary of available measures, keyed on constructor, run measures(). \n\nTraits\n\nconsumes_multiple_observations = true\ncan_report_unaggregated = true\nkind_of_proxy = LearnAPI.Distribution()\nobservation_scitype = Union{Missing, ScientificTypesBase.Infinite, ScientificTypesBase.Finite}\ncan_consume_tables = false\nsupports_weights = true\nsupports_class_weights = true\norientation = StatisticalMeasuresBase.Score()\nexternal_aggregation_mode = StatisticalMeasuresBase.Mean()\nhuman_name = spherical score\n\n\n\n\n\n","category":"function"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"StatisticalMeasuresBase.unwrap\nStatisticalMeasuresBase.is_measure\nStatisticalMeasuresBase.consumes_multiple_observations\nStatisticalMeasuresBase.can_report_unaggregated\nStatisticalMeasuresBase.kind_of_proxy\nStatisticalMeasuresBase.observation_scitype\nStatisticalMeasuresBase.can_consume_tables\nStatisticalMeasuresBase.supports_weights\nStatisticalMeasuresBase.supports_class_weights\nStatisticalMeasuresBase.orientation\nStatisticalMeasuresBase.external_aggregation_mode\nStatisticalMeasuresBase.human_name\nStatisticalMeasuresBase.supports_missings_measure\nStatisticalMeasuresBase.fussy_measure\nStatisticalMeasuresBase.aggregate\nStatisticalMeasuresBase.AggregationMode\nStatisticalMeasuresBase.check_weight_support\nStatisticalMeasuresBase.check_pools\nStatisticalMeasuresBase.check_numobs","category":"page"},{"location":"reference/#StatisticalMeasuresBase.unwrap","page":"Reference","title":"StatisticalMeasuresBase.unwrap","text":"StatisticalMeasuresBase.unwrap(measure)\n\nRemove one layer of wrapping from measure. If not wrapped, return measure.\n\nSee also StatisticalMeasuresBase.unfussy.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.is_measure","page":"Reference","title":"StatisticalMeasuresBase.is_measure","text":"StatisticalMeasuresBase.is_measure(m)\n\nReturns true if m is a measure, as defined below.\n\nAn object m has measure calling syntax if it is a function or other callable with the following signatures:\n\nm(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights)\n\nOnly the first signature is obligatory.\n\nOf course m could be an instance of some type with parameters.\n\nIf, additionally, m returns an (aggregated) measurement, where y has the interpretation of one or more ground truth target observations, and ŷ corresponding to one or more predictions or proxies of predictions (such as probability distributions), then m is a measure.  The terms \"target\" and \"proxy\" are used here in the sense of LearnAPI.jl.\n\nWhat qualifies as a \"measurement\" is not formally defined, but this is typically a Real number; other use-cases are matrices (e.g., confusion matrices) and dictionaries (e.g., mutli-class true positive counts).\n\nArguments\n\nFor m to be a valid measure, it will handle arguments of one of the following forms:\n\ny is either:\na single ground truth observation of some variable, the \"target\", or\nan object implementing the getobs/numobs interface in MLUtils.jl, and consisting of multiple target observations\nŷ is correspondingly:\na single target prediction or proxy for a prediction, such as a probability distribution, or\nan object implementing the getobs/numobs interface in MLUtils.jl, and consisting of multiple target (proxy) predictions, with numobs(ŷ) == numobs(y) - or is a single object, such as a joint probability distribution. The latter case should be clarified by an appropriate StatisticalMeasuresBase.kind_of_proxy(measure) declaration.\nweights, applying only in the multiple observation case, is an arbitrary iterable collection with a length, generating n Real elements, where n ≥ MLUtils.numobs(y).\nclass_weights is an arbitrary AbstractDict with Real values, whose keys include all possible observations in y.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.consumes_multiple_observations","page":"Reference","title":"StatisticalMeasuresBase.consumes_multiple_observations","text":"StatisticalMeasuresBase.consumes_multiple_observations(measure)\n\nReturns true if the ground truth target y appearing in calls like measure(ŷ, y) is expected to support the MLUtils.jl getobs/numobs interface, which includes all arrays and some tables.\n\nIf StatisticalMeasuresBase.kind_of_proxy(measure) <: LearnAPI.IID (the typical case) then a true value for this measure trait also implies ŷ is expected to be an MLUtils.jl data container with the same number of observations as y.\n\nNew implementations\n\nOverload this trait for a new measure type that consumes multiple observations, unless it has been constructed using multimeaure or is an StatisticalMeasuresBase.jl wrap thereof. The general fallback returns false but it is true for any multimeasure, and the value is propagated by other wrappers.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.can_report_unaggregated","page":"Reference","title":"StatisticalMeasuresBase.can_report_unaggregated","text":"StatisticalMeasuresBase.can_report_unaggregated(measure)\n\nReturns true if measure can report individual measurements, one per ground truth observation. Such unaggregated measurements are obtained using measurements instead of directly calling the measure on data.\n\nIf the method returns false, measurements returns the single aggregated measurement returned by calling the measure on data, but repeated once for each ground truth observation.\n\nNew implementations\n\nOverloading the trait is optional and it is typically not overloaded. The general fallback returns false but it is true for any multimeasure, and the value is propagated by other wrappers.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.kind_of_proxy","page":"Reference","title":"StatisticalMeasuresBase.kind_of_proxy","text":"StatisticalMeasuresBase.kind_of_proxy(measure)\n\nReturn the kind of proxy ŷ for target predictions expected in calls of the form measure(ŷ, y, args...; kwargs...).\n\nTypical return values are LearnAPI.LiteralTarget(), when ŷ is expected to have the same form as ŷ, or LearnAPI.Distribution(), when the observations in ŷ are expected to represent probability density/mass functions. For other kinds of proxy, see the LearnAPI.jl documentation.\n\nNew implementations\n\nOptional but strongly recommended. The return value must be a subtype of LearnAPI.KindOfProxy from the package LearnAPI.jl.\n\nThe fallback returns nothing.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.observation_scitype","page":"Reference","title":"StatisticalMeasuresBase.observation_scitype","text":"StatisticalMeasuresBase.observation_scitype(measure)\n\nReturns an upper bound on the allowed scientific type of a single ground truth observation passed to measure. For more on scientific types, see the ScientificTypes.jl documentation.\n\nSpecifically, if the scitype of every element of observations = [MLUtils.eachobs(y)...] is bounded by the method value, then that guarantees that measure(ŷ, y; args...; kwargs...) will succeed, assuming y is suitably compatible with the other arguments.\n\nSupport for tabular data\n\nIf StatisticalMeasuresBase.can_consume_tables(measure) is true, then y can additionally be any table, so long as vec(collect(row)) makes sense for every row in observations (e.g., y is a DataFrame) and is bounded by the scitype returned by observation_scitype(measure).\n\nAll the behavior outlined above assumes StatisticalMeasuresBase.consumes_multiple_observations(measure) is true. Otherwise, the return value has no meaning.\n\nNew implementations\n\nOptional but strongly recommended for measure than consume multiple observations. The fallback returns Union{}.\n\nExamples of return values are Union{Finite,Missing}, for CategoricalValue observations with possible missing values, or AbstractArray{<:Infinite}, for observations that are arrays with either Integer or AbstractFloat eltype. Scientific types can be imported from ScientificTypesBase.jl; see also the ScientificTypes.jl documentation. .\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.can_consume_tables","page":"Reference","title":"StatisticalMeasuresBase.can_consume_tables","text":"StatisticalMeasuresBase.can_consume_tables(measure)\n\nReturn true if y and ŷ in a call like measure(ŷ, y) can be a certain kind of table (e.g., a DataFrame). See StatisticalMeasuresBase.observation_scitype for details.\n\nNew implementations\n\nOptional. The main use case is measures of the form multimeasure(atom, transform=vec∘collect), where atom is a measure consuming vectors. See multimeasure for an example. For such measures the trait can be overloaded to return true.\n\nThe fallback returns false.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.supports_weights","page":"Reference","title":"StatisticalMeasuresBase.supports_weights","text":"StatisticalMeasuresBase.supports_weights(measure)\n\nReturn true if the measure supports per-observation weights, which must be AbstractVector{<:Real}.\n\nNew implementations\n\nThe fallback returns false. The trait is true for all multimeasures.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.supports_class_weights","page":"Reference","title":"StatisticalMeasuresBase.supports_class_weights","text":"StatisticalMeasuresBase.supports_class_weights(measure)\n\nReturn true if the measure supports class weights, which must be dictionaries of Real values keyed on all possible values of targets y passed to the measure.\n\nNew implementations\n\nThe fallback returns false. The trait is true for all multimeasures.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.orientation","page":"Reference","title":"StatisticalMeasuresBase.orientation","text":"StatisticalMeasuresBase.orientation(measure)\n\nReturns:\n\nStatisticalMeasuresBase.Score(), if measure is likely the basis of optimizations in which the measure value is always maximized\nStatisticalMeasuresBase.Loss(), if measure is likely the basis of optimizations in which the  measure value is always minimized\nStatisticalMeasuresBase.Unoriented(), in any other case\n\nNew implementations\n\nThis trait should be overloaded for measures likely to be used in optimization.\n\nThe fallback returns Unoriented().\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.external_aggregation_mode","page":"Reference","title":"StatisticalMeasuresBase.external_aggregation_mode","text":"StatisticalMeasuresBase.external_aggregation_mode(measure)\n\nReturns the preferred mode for aggregating measurements generated by applications of the measure on multiple sets of data. This can be useful to know when aggregating separate measurements in a cross-validation scheme. It is also the default aggregation mode used when wrapping a measure using multimeasure.\n\nSee also aggregate, multimeasure\n\nNew implementations\n\nThis optional trait has a fallback returning Mean(). Possible values are instances of subtypes of StatisticalMeasuresBase.AggregationMode.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.human_name","page":"Reference","title":"StatisticalMeasuresBase.human_name","text":"StatisticalMeasuresBase.human_name(measure)\n\nA human-readable string representation of typeof(measure). Primarily intended for auto-generation of documentation.\n\nNew implementations\n\nOptional. A fallback takes the type name, inserts spaces and removes capitalization. For example, FScore becomes \"f score\". Better might be to overload the trait     to return \"F-score\".\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.supports_missings_measure","page":"Reference","title":"StatisticalMeasuresBase.supports_missings_measure","text":"supports_missings_measure(atomic_measure)\n\nReturn a new measure, measure, with the same behavior as atomic_measure, but supporting missing as a value for ŷ or y in calls like measure(ŷ, y, args...), or in applications of measurements.  Missing values are propagated by the wrapped measure (but may be skipped in subsequent wrapping or aggregation).\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.fussy_measure","page":"Reference","title":"StatisticalMeasuresBase.fussy_measure","text":"fussy_measure(measure; extra_check=nothing)\n\nReturn a new measure, fussy, with the same behavior as measure, except that calling fussy on data, or calling measuremnts on fussy and data, will will additionally:\n\nCheck that if weights or class_weights are specified, then measure supports them (see StatisticalMeasuresBase.check_weight_support)\nCheck that ŷ (predicted proxy), y (ground truth), weights and class_weights are compatible, from the point of view of observation counts and class pools, if relevant (see and StatisticalMeasuresBase.check_numobs and StatisticalMeasuresBase.check_pools).\nCall extra_check(measure, ŷ, y[, weights, class_weights]), unless extra_check==nothing. Note the first argument here is measure, not atomic_measure.\n\nDo not use fussy_measure unless both y and ŷ are expected to implement the MLUtils.jl getobs/numbos interface (e.g., are AbstractArrays)\n\nSee also StatisticalMeasuresBase.measurements, StatisticalMeasuresBase.is_measure\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.aggregate","page":"Reference","title":"StatisticalMeasuresBase.aggregate","text":"aggregate(itr; weights=nothing, mode=Mean(), skipnan=false)\n\nAggregate the values generated by the iterator, itr, using the specified aggregation mode and optionally specified numerical weights.\n\nAny missing values in itr are skipped before aggregation, but will still count towards normalization factors. So, if the return type has a zero, it's as if we replace the missings with zeros.\n\nThe values to be aggregated must share a type for which +, * / and ^ (RootMean case) are defined, or can be dictionaries whose value-type is so equipped.\n\nKeyword options\n\nweights=nothing: An iterator with a length, generating Real elements, or nothing\nmode=Mean(): Options include Mean() and Sum(); see StatisticalMeasuresBase.AggregationMode for all options and their meanings. Using Mean() in conjunction with weights returns the usual weighted mean scaled by the average weight value. \nskipnan=false: Whether to skip NaN values in addition to missing values\naggregate=true: If false then itr is just multiplied by any specified weights, and collected.\n\nExample\n\nSuppose a 3-fold cross-validation algorithm delivers root mean squared errors given by errors below, and that the folds have the specified sizes. Then μ below is the appropriate error aggregate.\n\nerrors = [0.1, 0.2, 0.3]\nsizes = [200, 200, 150]\nweights = 3*sizes/sum(sizes)\n@assert mean(weights) ≈ 1\nμ = aggregate(errors; weights, mode=RootMean())\n@assert μ ≈ (200*0.1^2 + 200*0.2^2 + 150*0.3^2)/550 |> sqrt\n\n\n\naggregate(f, itr; options...)\n\nInstead, aggregate the results of broadcasting f over itr. Weight multiplication is fused with the broadcasting operation, so this method is more efficient than separately broadcasting, weighting, and aggregating.\n\nThis method has the same keyword options as above.\n\nExamples\n\nitr = [(1, 2), (2, 3), (4, 3)]\n\njulia> aggregate(t -> abs(t[1] - t[2]), itr, weights=[10, 20, 30], mode=Sum())\n60\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.AggregationMode","page":"Reference","title":"StatisticalMeasuresBase.AggregationMode","text":" StatisticalMeasuresBase.AggregationMode\n\nAbstract type for modes of aggregating weighted or unweighted measurements. An aggregation mode is one of the following concrete instances of this type (when unspecified, weights are unit weights):\n\nMean(): Compute the mean value of the weighted measurements. Equivalently, compute the usual weighted mean and multiply by the average weight. To get a true weighted mean, re-scale weights to average one, or use IMean() instead.\nSum(): Compute the usual weighted sum.\nRootMean(): Compute the squares of all measurements, compute the weighted Mean() of these, and apply the square root to the result.\nRootMean(p) for some real p > 0: Compute the obvious generalization of RootMean() with RootMean() = RootMean(2).\nIMean(): Compute the usual weighted mean, which is insensitive to weight rescaling.\n\n\n\n\n\n","category":"type"},{"location":"reference/#StatisticalMeasuresBase.check_weight_support","page":"Reference","title":"StatisticalMeasuresBase.check_weight_support","text":"check_weight_support(measure, weight_args...)\n\nCheck if measure supports calls of the form measure(ŷ, y, weight_args...). Will always accept nothing as one or both weight arguments. A failed check throws an exception.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.check_pools","page":"Reference","title":"StatisticalMeasuresBase.check_pools","text":"check_pools(A::UnivariateFiniteArray, B::CategoricalArrays.CatArrOrSub)\n\nCheck that the class pool of A coincides with the class pool of B, as sets. If both A and B are ordered, check the pools have the same ordering.\n\nIf a check fails, throw an exception, and otherwise return nothing.\n\n\n\n\n\ncheck_pools(A, B)\n\nIf A and B are both CategoricalArrays (or views thereof) check they have the same class pool. If both A and B are ordered, check the pools have the same ordering.\n\nIf B an abstract dictionary, check the key set of B agrees with the class pool of A, in the case A is a CategoricalArray. Otherwise, check it agrees with unique(skipmissing(A)).\n\nOtherwise perform no checks.\n\nIf a check fails throw an exception.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasuresBase.check_numobs","page":"Reference","title":"StatisticalMeasuresBase.check_numobs","text":"    check_numobs(X, Y)\n\nCheck if two objects X and Y supporting the MLJUtils.jl numobs interface have the same number of observations. If they don't, throw an exception.\n\n\n\n\n\n","category":"function"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [Functions,]","category":"page"},{"location":"reference/#StatisticalMeasures.Functions._idx_unique_sorted-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions._idx_unique_sorted","text":"_idx_unique_sorted(v)\n\nPrivate method.\n\nReturn the index of unique elements in Real vector v under the assumption that the vector v is sorted in decreasing order.\n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.accuracy-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.accuracy","text":"Functions.accuracy(m)\n\nReturn the accuracy for the the matrix m, interpreted as a confusion matrix.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.auc-Tuple{Any, Any, Any}","page":"Reference","title":"StatisticalMeasures.Functions.auc","text":"Functions.auc(probabilities_of_positive, ground_truth_observations, positive_class)\n\nReturn the area under the ROC (receiver operator characteristic). Implementation is based on the Mann-Whitney U statistic.  See the Whitney U test Wikipedia page for details. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.false_discovery_rate-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.false_discovery_rate","text":"Functions.false_discovery_rate(m)\n\nReturn the false discovery rate for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.false_negative-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.false_negative","text":"Functions.false_negative(m)\n\nReturn  the false negative count for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.false_negative_rate-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.false_negative_rate","text":"Functions.false_negative_rate(m)\n\nReturn the false negative rate for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.false_positive-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.false_positive","text":"Functions.false_positive(m)\n\nReturn  the false positive count for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.false_positive_rate-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.false_positive_rate","text":"Functions.false_positive_rate(m)\n\nReturn the false positive rate for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.fscore","page":"Reference","title":"StatisticalMeasures.Functions.fscore","text":"Functions.fscore(m, β=1.0)\n\nReturn the F_β score of the matrix m, interpreted as a confusion matrix. The first index corresponds to the \"negative\" class, the second to the \"positive\".\n\nAssumes m is a 2 x 2 matrix but does not check this.\n\n\n\n\n\n","category":"function"},{"location":"reference/#StatisticalMeasures.Functions.kappa-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.kappa","text":"Functions.kappa(m)\n\nReturn  kappa for the the matrix m, interpreted as a confusion matrix.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.matthews_correlation-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.matthews_correlation","text":"Functions.matthews_correlation(m)\n\nReturn  Matthew's correlation for the the matrix m, interpreted as a confusion matrix.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_false_discovery_rate-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_false_discovery_rate","text":"Functions.multiclass_false_discovery_rate(m, average[, weights])\n\nReturn the one-versus-rest false discovery rates for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_false_negative-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_false_negative","text":"Functions.multiclass_false_negative(m)\n\nReturn the one-versus-rest false negative counts for the the matrix m, interpreted as a confusion matrix.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_false_negative_rate-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_false_negative_rate","text":"Functions.multiclass_false_negative_rate(m, average[, weights])\n\nReturn the one-versus-rest false negative rates for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_false_positive-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_false_positive","text":"Functions.multiclass_false_positive(m)\n\nReturn the one-versus-rest false positive counts for the the matrix m, interpreted as a confusion matrix.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_false_positive_rate-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_false_positive_rate","text":"Functions.multiclass_false_positive_rate(m, average[, weights])\n\nReturn the one-versus-rest false positive rates for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_fscore-Tuple{Any, Any, MicroAvg}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_fscore","text":"Functions.multiclass_fscore(m, β, average[, weights])\n\nReturn the multiclass fscore for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this.  *\"  Note that the MicroAvg score is insenstive to β. \"\n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_negative_predictive_value-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_negative_predictive_value","text":"Functions.multiclass_negative_predictive_value(m, average[, weights])\n\nReturn the one-versus-rest negative predictive values for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_positive_predictive_value-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_positive_predictive_value","text":"Functions.multiclass_positive_predictive_value(m, average[, weights])\n\nReturn the one-versus-rest positive predictive values for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_true_negative-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_true_negative","text":"Functions.multiclass_true_negative(m)\n\nReturn the one-versus-rest true negative counts for the the matrix m, interpreted as a confusion matrix.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_true_negative_rate-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_true_negative_rate","text":"Functions.multiclass_true_negative_rate(m, average[, weights])\n\nReturn the one-versus-rest true negative rates for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_true_positive-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_true_positive","text":"Functions.multiclass_true_positive(m)\n\nReturn the one-versus-rest true positive counts for the the matrix m, interpreted as a confusion matrix.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.multiclass_true_positive_rate-Tuple{Any, Any, Vararg{Any}}","page":"Reference","title":"StatisticalMeasures.Functions.multiclass_true_positive_rate","text":"Functions.multiclass_true_positive_rate(m, average[, weights])\n\nReturn the one-versus-rest true positive rates for the the matrix m, interpreted as a confusion matrix. Here average is one of: NoAvg(), MicroAvg(), MacroAvg(); weights is a vector of class weights. Usual weighted means, and not means of weighted sums, are used. Weights are not supported by the Micro() option.\n\nAssumes m is a square matrix, but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.negative_predictive_value-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.negative_predictive_value","text":"Functions.negative_predictive_value(m)\n\nReturn the negative predictive value for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.positive_predictive_value-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.positive_predictive_value","text":"Functions.positive_predictive_value(m)\n\nReturn the positive predictive value for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.roc_curve-Tuple{Any, Any, Any}","page":"Reference","title":"StatisticalMeasures.Functions.roc_curve","text":"Functions.roc_curve(probs_of_positive, ground_truth_obs, positive_class) ->\n    false_positive_rates, true_positive_rates, thresholds\n\nReturn data for plotting the receiver operator characteristic (ROC curve) for a binary classification problem.\n\nIf there are k unique probabilities, then there are correspondingly k thresholds and k+1 \"bins\" over which the false positive and true positive rates are constant.:\n\n[0.0 - thresholds[1]]\n[thresholds[1] - thresholds[2]]\n...\n[thresholds[k] - 1]\n\nConsequently, true_positive_rates and false_positive_rates have length k+1 if thresholds has length k.\n\nTo plot the curve using your favorite plotting backend, do something like plot(false_positive_rates, true_positive_rates).\n\nAssumes there are no more than two classes but does not check this. Does not check that positive_class is one of the observed classes.\n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.true_negative-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.true_negative","text":"Functions.true_negative(m)\n\nReturn  the true negative count for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.true_negative_rate-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.true_negative_rate","text":"Functions.true_negative_rate(m)\n\nReturn the true negative rate for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.true_positive-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.true_positive","text":"Functions.true_positive(m)\n\nReturn  the true positive count for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"reference/#StatisticalMeasures.Functions.true_positive_rate-Tuple{Any}","page":"Reference","title":"StatisticalMeasures.Functions.true_positive_rate","text":"Functions.true_positive_rate(m)\n\nReturn the true positive rate for the the matrix m, interpreted as a confusion matrix.\n\nThe first index corresponds to the \"negative\" class, the second to the \"positive\" class.\n\nAssumes m is a 2 x 2 matrix but does not check this. \n\n\n\n\n\n","category":"method"},{"location":"confusion_matrices/#Confusion-Matrices","page":"Confusion Matrices","title":"Confusion Matrices","text":"","category":"section"},{"location":"confusion_matrices/","page":"Confusion Matrices","title":"Confusion Matrices","text":"Users typically construct confusion matrices using the confmat measure, or other variants that can be constructed using the ConfusionMatrix constructor. See Examples of Usage for examples. (A pure function version of confmat, with options, is ConfusionMatrices.confmat.)","category":"page"},{"location":"confusion_matrices/","page":"Confusion Matrices","title":"Confusion Matrices","text":"The ConfusionMatrices submodule of StatisticalMeasures.jl provides some methods for extracting data from these matrices, detailed below.","category":"page"},{"location":"confusion_matrices/","page":"Confusion Matrices","title":"Confusion Matrices","text":"method description\ncm[i, j] count for a  ith class prediction and jth class ground truth\ncm(p, g) count for a  class p prediction and class g ground truth\nConfusionMatrices.matrix(cm) return the raw matrix associated with confusion matrix cm\nConfusionMatrices.isordered(cm) true if levels of cm have been explicitly ordered\nConfusionMatrices.levels(cm) return the target levels (classes) associated with cm","category":"page"},{"location":"confusion_matrices/#Reference","page":"Confusion Matrices","title":"Reference","text":"","category":"section"},{"location":"confusion_matrices/","page":"Confusion Matrices","title":"Confusion Matrices","text":"ConfusionMatrices.matrix\nConfusionMatrices.isordered\nConfusionMatrices.levels\nConfusionMatrices.ConfusionMatrix\nConfusionMatrices.confmat","category":"page"},{"location":"confusion_matrices/#StatisticalMeasures.ConfusionMatrices.matrix","page":"Confusion Matrices","title":"StatisticalMeasures.ConfusionMatrices.matrix","text":"ConfusionMatrices.matrix(m::ConfusionMatrix; warn=true)\n\nReturn the regular Matrix associated with confusion matrix m.\n\n\n\n\n\n","category":"function"},{"location":"confusion_matrices/#CategoricalArrays.isordered","page":"Confusion Matrices","title":"CategoricalArrays.isordered","text":"ConfusionMatrices.isordered(m::ConfusionMatrix)\n\nReturn true if and only if the levels associated with m have been explicitly ordered.\n\n\n\n\n\n","category":"function"},{"location":"confusion_matrices/#DataAPI.levels","page":"Confusion Matrices","title":"DataAPI.levels","text":"levels(m::ConfusionMatrices.ConfusionMatrix)\n\nReturn the levels associated with the confusion matrix m, in the order consistent with the regular matrix returned by ConfusionMatrices.matrix(cm).\n\n\n\n\n\n","category":"function"},{"location":"confusion_matrices/#StatisticalMeasures.ConfusionMatrices.ConfusionMatrix","page":"Confusion Matrices","title":"StatisticalMeasures.ConfusionMatrices.ConfusionMatrix","text":"ConfusionMatrices.ConfusionMatrix{N,O,L}\n\nWrapper type for confusion matrices.\n\nType parameters\n\nN ≥ 2: number of levels (classes)\nO: true if levels are explicitly understood to be ordered\nL: type of labels\n\nPredicted classes are constant on rows, ground truth classes are constant on columns. \n\nSee the Confusion matrix wikipedia article for more information.\n\nPublic interface\n\nInstances can be constructed directly using the ConfusionMatrix constructor (two methods documented below) or, more typically, using ConfusionMatrices.confmat. Other methods are: ConfusionMatrices.matrix (to extract raw matrix), levels, and isordered.\n\nTwo instances are considered == if:\n\nThe associated levels agree, as sets\nIf both instances are ordered, then the levels also agree as vectors\nAccess-by-level behaviour is the same (see below)\n\nInstances need not have the same underlying matrix to be ==.\n\nAccess elements via level as shown in this example:\n\nimport StatisticalMeasures.ConfusionMatrices as CM\n\ny = [\"a\", \"b\", \"a\", \"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\nŷ = [\"b\", \"a\", \"a\", \"b\", \"a\", \"b\", \"b\", \"b\", \"a\", \"a\"]\n\njulia> cm = CM.confmat(ŷ, y)\n              ┌───────────────────────────┐\n              │       Ground Truth        │\n┌─────────────┼─────────────┬─────────────┤\n│  Predicted  │      a      │      b      │\n├─────────────┼─────────────┼─────────────┤\n│      a      │      2      │      3      │\n├─────────────┼─────────────┼─────────────┤\n│      b      │      4      │      1      │\n└─────────────┴─────────────┴─────────────┘\n\n\njulia> cm(\"a\", \"b\")\n3\n\nAccess by index is also possible, if the confusion matrix is ordered. Otherwise, you can first extract the underlying matrix with ConfusionMatrices.matrix. For options creating ordered confusion matrices, see ConfusionMatrices.confmat.\n\n\n\n\n\n","category":"type"},{"location":"confusion_matrices/#StatisticalMeasures.ConfusionMatrices.confmat","page":"Confusion Matrices","title":"StatisticalMeasures.ConfusionMatrices.confmat","text":"ConfusionMatrices.confmat(ŷ, y, levels=nothing, rev=false, perm=nothing, checks=true)\n\nReturn the confusion matrix corresponding to predictions ŷ and ground truth observations y. Whenever missing occurs the corresponding prediction-ground-truth pair is skipped in the counting.\n\nElements of a confusion matrix can always be accessed by level - see the example below. To flag the confusion matrix as ordered, and hence index-accessible, do one of the following:\n\nSupply ordered CategoricalArray inputs ŷ and y\nExplicitly specify levels or one of rev, perm\n\nNote that == for two confusion matrices is stricter when both are ordered.\n\nMethod is optimized for CategoricalArray inputs with levels inferred. In that case levels will be the complete internal class pool, and not just the observed levels.\n\nimport StatisticalMeasures.ConfusionMatrices as CM\n\ny = [\"a\", \"b\", \"a\", \"a\", \"b\", \"a\", \"a\", \"b\", \"b\", \"a\"]\nŷ = [\"b\", \"a\", \"a\", \"b\", \"a\", \"b\", \"b\", \"b\", \"a\", \"a\"]\n\njulia> cm = CM.confmat(ŷ, y)\n              ┌───────────────────────────┐\n              │       Ground Truth        │\n┌─────────────┼─────────────┬─────────────┤\n│  Predicted  │      a      │      b      │\n├─────────────┼─────────────┼─────────────┤\n│      a      │      2      │      3      │\n├─────────────┼─────────────┼─────────────┤\n│      b      │      4      │      1      │\n└─────────────┴─────────────┴─────────────┘\n\n\njulia> cm(\"a\", \"b\")\n3\n\njulia> CM.matrix(cm)\n┌ Warning: Confusion matrix levels not explicitly ordered. Using the order, [\"a\", \"b\"].\n└ @ StatisticalMeasures.ConfusionMatrices ~/MLJ/StatisticalMeasures/src/confusion_matrices.jl:120\n2×2 Matrix{Int64}:\n 2  3\n 4  1\n\nordered_cm = CM.confmat(ŷ, y, levels=[\"b\", \"a\"])\n\njulia> ordered_cm(\"a\", \"b\")\n3\n\njulia> CM.matrix(ordered_cm)\n2×2 Matrix{Int64}:\n 1  4\n 3  2\n\njulia> ordered_cm[2, 1]\n3\n\n\nKeyword options\n\nlevels::Union{Vector,Nothing}=nothing: if nothing, levels are inferred from  ŷ and y and, by default, ordered according to the element type of y.\nrev=false: in the case of binary data, whether to reverse the levels (as inferred or specified); a nothing value is the same as false.\n\nperm=nothing: in the general case, a permutation representing a re-ordering of levels (as inferred or specified); e.g., perm = [1,3,2] for data with three classes.\n\nchecks=true: when true, specified levels are checked to see they include all observed levels; set to false for speed.\n\nSee also ConfusionMatrices.ConfusionMatrix, and the Confusion matrix wikipedia article.\n\n\n\n\n\n","category":"function"},{"location":"","page":"Overview","title":"Overview","text":"<script async defer src=\"https://buttons.github.io/buttons.js\"></script>\n\n<div style=\"font-size:1.4em;font-weight:bold;\">\n  <a href=\"https://juliaai.github.io/StatisticalMeasures.jl/dev/auto_generated_list_of_measures#aliases\"\n    style=\"color: #9558B2;\">List of measures</a>           &nbsp;|&nbsp;\n  <a href=\"examples_of_usage\"\n    style=\"color: #389826;\">Examples</a>\n</div>\n\n<span style=\"color: #9558B2;font-size:4.5em;\">\nStatisticalMeasures.jl</span>\n<br>\n<span style=\"color: #9558B2;font-size:1.6em;font-style:italic;\">\nMeasures (metrics) for statistics and machine learning</span>\n<br><br>","category":"page"},{"location":"#Overview","page":"Overview","title":"Overview","text":"","category":"section"},{"location":"","page":"Overview","title":"Overview","text":"This package defines common measures (metrics) for classification and regression problems in statistics and machine learning. To see if your favorite measure is implemented, see this list. Some multi-target measures are included, but see also Custom multi-target measures.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"Measures with parameters (e.g., the L^p loss) are realized as callable instances of a struct; calling syntax complies with the specification in StatisticalMeasuresBase.jl.","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"In addition to the measures themselves, this package provides:","category":"page"},{"location":"","page":"Overview","title":"Overview","text":"A tool roc_curve for plotting Receiver Operator Characteristics\nAn extension module allowing measures from LossFunctions.jl to be used and extended using the same syntax as other measures. See Using losses from LossFunctions.jl.\nA submodule ConfusionMatrices providing a confusion matrix type and basic functionality.\nA submodule Functions where some core measure implementations are factored out as pure functions.","category":"page"},{"location":"examples_of_usage/#Examples-of-Usage","page":"Examples of usage","title":"Examples of Usage","text":"","category":"section"},{"location":"examples_of_usage/#calling","page":"Examples of usage","title":"Calling syntax","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"A measure m is called with this syntax:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"m(ŷ, y)\nm(ŷ, y, weights)\nm(ŷ, y, class_weights::AbstractDict)\nm(ŷ, y, weights, class_weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"where y is ground truth and ŷ predictions. This package provides measure constructors, such as BalancedAccuracy:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\nusing StatisticalMeasures\n\nm = BalancedAccuracy(adjusted=true)\nm([\"O\", \"X\", \"O\", \"X\"], [\"X\", \"X\", \"X\", \"O\"], [1, 2, 1, 2])","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Aliases are provided for commonly applied instances:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"bacc == BalancedAccuracy() == BalancedAccuracy(adjusted=false)","category":"page"},{"location":"examples_of_usage/#Contents","page":"Examples of usage","title":"Contents","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Binary classification\nMulti-class classification\nProbabilistic classification\nNon-probabilistic regression\nProbabilistic regression\nCustom multi-target measures\nUsing losses from LossFunctions.jl\nMeasure search (experimental feature)","category":"page"},{"location":"examples_of_usage/#Binary-classification","page":"Examples of usage","title":"Binary classification","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\nusing CategoricalArrays\n\n# ground truth:\ny = categorical(\n        [\"X\", \"X\", \"X\", \"O\", \"X\", \"X\", \"O\", \"O\", \"X\"],\n        ordered=true,\n)\n\n# prediction:\nŷ = categorical(\n   [\"O\", \"X\", \"O\", \"X\", \"O\", \"O\", \"O\", \"X\", \"X\"],\n   levels=levels(y),\n   ordered=true,\n)\n\naccuracy(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"weights = [1, 2, 1, 2, 1, 2, 1, 2, 1]\naccuracy(ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"class_weights = Dict(\"X\" => 10, \"O\" => 1)\naccuracy(ŷ, y, class_weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"accuracy(ŷ, y, weights, class_weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"To get a measurement for each individual observation, use measurements:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"measurements(accuracy, ŷ, y, weights, class_weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"kappa(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"mat = confmat(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Some measures can be applied directly to confusion matrices:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"kappa(mat)","category":"page"},{"location":"examples_of_usage/#Multi-class-classification","page":"Examples of usage","title":"Multi-class classification","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\nusing CategoricalArrays\nimport Random\nRandom.seed!()\n\ny = rand(\"ABC\", 1000) |> categorical\nŷ = rand(\"ABC\", 1000) |> categorical\nclass_weights = Dict('A' => 1, 'B' =>2, 'C' => 10)\nMulticlassFScore(beta=0.5, average=MacroAvg())(ŷ, y,  class_weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"MulticlassFScore(beta=0.5, average=NoAvg())(ŷ, y,  class_weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Unseen classes are tracked, when using CategoricalArrays, as here:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"# find 'C'-free indices\nmask = y .!= 'C' .&& ŷ .!= 'C';\n# remove observations with 'C' class::\ny = y[mask]\nŷ = ŷ[mask]\n'C' in y ∪ ŷ","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"confmat(ŷ, y)","category":"page"},{"location":"examples_of_usage/#Probabilistic-classification","page":"Examples of usage","title":"Probabilistic classification","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"To mitigate ambiguity around representations of predicted probabilities, a probabilistic prediction of categorical data is expected to be represented by a UnivariateFinite distribution, from the package CategoricalDistributions.jl. This is the form delivered, for example, by MLJ classification models.","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\nusing CategoricalArrays\nusing CategoricalDistributions\n\ny = categorical([\"X\", \"O\", \"X\", \"X\", \"O\", \"X\", \"X\", \"O\", \"O\", \"X\"], ordered=true)\nX_probs = [0.3, 0.2, 0.4, 0.9, 0.1, 0.4, 0.5, 0.2, 0.8, 0.7]\nŷ = UnivariateFinite([\"O\", \"X\"], X_probs, augment=true, pool=y)\nŷ[1]","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"auc(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"measurements(log_loss, ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"measurements(brier_score, ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"We note in passing that mode and pdf methods can be applied to UnivariateFinite distributions. So, for example, we can do:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"confmat(mode.(ŷ), y)","category":"page"},{"location":"examples_of_usage/#Non-probabilistic-regression","page":"Examples of usage","title":"Non-probabilistic regression","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\n\ny = [0.1, -0.2, missing, 0.7]\nŷ = [-0.2, 0.1, 0.4, 0.7]\nrsquared(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"weights = [1, 3, 2, 5]\nrms(ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"measurements(LPLoss(p=2.5), ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Here's an example of a multi-target regression measure, for data with 3 observations of a 2-component target:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"# last index is observation index:\ny = [1 2 3; 2 4 6]\nŷ = [2 3 4; 4 6 8]\nweights = [8, 7, 6]\nŷ - y","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"MultitargetLPLoss(p=2.5)(ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"# one \"atomic weight\" per component of target:\nMultitargetLPLoss(p=2.5, atomic_weights = [1, 10])(ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Some tabular formats (e.g., DataFrame) are also supported:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using Tables\nt = y' |> Tables.table |> Tables.rowtable\nt̂ = ŷ' |> Tables.table |> Tables.rowtable\nMultitargetLPLoss(p=2.5)(ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/#Probabilistic-regression","page":"Examples of usage","title":"Probabilistic regression","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\nimport Distributions:Poisson, Normal\nimport Random.seed!\nseed!()\n\ny = rand(20)\nŷ = [Normal(rand(), 0.5) for i in 1:20]\nŷ[1]","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"log_loss(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"weights = rand(20)\nlog_loss(ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"weights = rand(20)\nmeasurements(log_loss, ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"An example with Count (integer) data:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"y = rand(1:10, 20)\nŷ = [Poisson(10*rand()) for i in 1:20]\nŷ[1]","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"brier_loss(ŷ, y)","category":"page"},{"location":"examples_of_usage/#Custom-multi-target-measures","page":"Examples of usage","title":"Custom multi-target measures","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Here's an example of constructing a multi-target regression measure, for data with 3 observations of a 2-component target:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\n\n# last index is observation index:\ny = [\"X\" \"O\" \"O\"; \"O\" \"X\" \"X\"]\nŷ = [\"O\" \"X\" \"O\"; \"O\" \"O\" \"O\"]","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"# if prescribed, we need one \"atomic weight\" per component of target:\nmultitarget_accuracy= multimeasure(accuracy, atomic_weights=[1, 2])\nmultitarget_accuracy(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"measurements(multitarget_accuracy, ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"# one weight per observation:\nweights = [1, 2, 10]\nmeasurements(multitarget_accuracy, ŷ, y, weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"See multimeasure for options. Refer to the StatisticalMeausureBase.jl documentation for advanced measure customization.","category":"page"},{"location":"examples_of_usage/#Using-losses-from-LossFunctions.jl","page":"Examples of usage","title":"Using losses from LossFunctions.jl","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"The margin losses in LossFunctions.jl can be regarded as binary probabilistic measures, but they cannot be directly called on CategoricalValues and UnivariateFinite distributions, as we do for similar measures provided by StatisticalMeasures (see Probabilistic classification above). If we want this latter behavior, then we need to wrap these losses using Measure:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\nimport LossFunctions as LF\n\nloss = Measure(LF.L1HingeLoss())","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"This loss can only be called on scalars (true for LossFunctions.jl losses since v0.10):","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using CategoricalArrays\nusing CategoricalDistributions\n\ny = categorical([\"X\", \"O\", \"X\", \"X\"], ordered=true)\nX_probs = [0.3, 0.2, 0.4, 0.9]\nŷ = UnivariateFinite([\"O\", \"X\"], X_probs, augment=true, pool=y)\nloss(ŷ[1], y[1])","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"This is remedied with the multimeasure wrapper:","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"import StatisticalMeasuresBase.Sum\n\nloss_on_vectors = multimeasure(loss, mode=Sum())\nloss_on_vectors(ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"class_weights = Dict(\"X\"=>1, \"O\"=>10)\nloss_on_vectors(ŷ, y, class_weights)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"measurements(loss_on_vectors, ŷ, y)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"Wrap again, as shown in the preceding section, to get a multi-target version.","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"For distance-based loss functions, wrapping in Measure is not strictly necessary, but does no harm.","category":"page"},{"location":"examples_of_usage/#Measure-search-(experimental-feature)","page":"Examples of usage","title":"Measure search (experimental feature)","text":"","category":"section"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"using StatisticalMeasures\nusing ScientificTypes\n\ny = rand(3)\nyhat = rand(3)\noptions = measures(yhat, y, supports_weights=true)","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"options[LPLoss]","category":"page"},{"location":"examples_of_usage/","page":"Examples of usage","title":"Examples of usage","text":"measures(\"Matthew\")","category":"page"}]
}
